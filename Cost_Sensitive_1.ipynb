{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cost Sensitive 1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPL+C1+/Fed1N3lgYHiggHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Cost_Sensitive_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSiXpY8v2UGr"
      },
      "source": [
        "# **Cost Sensitive Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPOiuU2X0syk"
      },
      "source": [
        "Machine learning errors have different costs. <br>\n",
        "**For example:** <br>\n",
        ">predicting someone has cancer when they don't is not nearly as costly as predicting someone does not have cancer when they do. <br><br>\n",
        "\n",
        "With imbalanced datasets different errors can have vastly different costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fptT3p5-Kbw3"
      },
      "source": [
        "Types of cost:<br>\n",
        "- cost of misclassification errors<br>\n",
        "- cost of tests or evaluation<br>\n",
        "- cost of labeling<br>\n",
        "- cost of intervention <br>\n",
        "- cost of unwanted acchievements or outcomes\n",
        "- cost of computatiion\n",
        "- cost of data collection\n",
        "- cost if human-computer interaction\n",
        "- cost of instability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRtFgoFJ1MPQ"
      },
      "source": [
        "Cost-sensitive techniques can be broken into three types:<br>\n",
        "- data sampling\n",
        "- algorithm modifications\n",
        "- ensemble methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLgXN9zp3CRz"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtJ9jpGU21nm"
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "from numpy import mean\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGsuFJAv3Fly"
      },
      "source": [
        "**Create an imbalanced dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QybLAsR9HaQh"
      },
      "source": [
        "weight_of_classes=[0.99,0.01]\n",
        "X, y = make_classification(n_classes = 2,n_samples=60000, n_features=2, n_redundant=0,\n",
        "      n_clusters_per_class=1, weights=weight_of_classes, flip_y=0, random_state=2)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKWCGzwrWqf-"
      },
      "source": [
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd47BF2WJ_KY"
      },
      "source": [
        "**Create a logistic regresssion model**<br>\n",
        "**Use Cross Validation to evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQjQiEY0XAao"
      },
      "source": [
        "# define model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp9Z-3nIMzjM"
      },
      "source": [
        "# **Weighted Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71XE9mCyM388"
      },
      "source": [
        "Use weighted logistic regression on an imbalanced dataset. <br>\n",
        "Each class label is given a weight for calculating cost."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You assign higher weight to those observations that are more important. This is equivalent to adding multiple copies of them to the dataset except it's more flexible as the weight can be a noninteger.\n",
        "\n",
        "One reason to give an observation a high weight is that it represents a group that is underrepresented in the sample."
      ],
      "metadata": {
        "id": "ezh19RPw30tG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrNXKpWmNag8"
      },
      "source": [
        "Weights are a hyperparameter that can be found:<br>\n",
        "- using a hyperparameter search\n",
        "- using an SME to set the cost\n",
        "- setting and using a best practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfsXYRkeN_Cq"
      },
      "source": [
        "Best practice:<br>\n",
        "Use inverse class distribution for the weights<br>\n",
        "In this example, the difference between the classes is 100 to 1, so we set the weights as 1 to 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmoBOxD3XH38"
      },
      "source": [
        "# define model\n",
        "weights = {0:0.01, 1:0.99}\n",
        "model = LogisticRegression(solver='lbfgs', class_weight=weights)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUsUDUQTeFVx"
      },
      "source": [
        "**Use compute_class_weight to get the weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xYi0-Y6XKmE"
      },
      "source": [
        "# calculate class weighting\n",
        "weighting = compute_class_weight('balanced', classes=[0,1], y=y)\n",
        "print(weighting)\n",
        "#.5 to 50 == 1 to 100 == .01 to 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxGmJleaevXC"
      },
      "source": [
        "**Can use class_weight='balanced' to balance the weights **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voABIOpMXQqD"
      },
      "source": [
        "# define model\n",
        "model = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNU870MlHJ0K"
      },
      "source": [
        "**Assignment**:<br>\n",
        "1. Change the size of the dataset. What happens to the scores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufj5i5SenA4W"
      },
      "source": [
        "**Assignment**: <br>\n",
        "Below is code for multi-class imbalanced datasets.<br>\n",
        "Substitute this code for the code above and rerun. What is the difference with multiclass classification? Try different ratios. What happens when the classes are balanced?<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqs1-ZnxKisp"
      },
      "source": [
        "weight_of_classes=[0.49,0.49,0.02]\n",
        "X, y = make_classification(n_classes = 3,n_samples=10000, n_features=2, n_redundant=0,\n",
        "      n_clusters_per_class=1, weights=weight_of_classes, flip_y=0, random_state=2)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC and AUC are used for binary classification**.\n",
        "To use these for multiclass classification, you have to modify the scoring parameter. <br>\n",
        "As you can see below it is now 'roc_auc_ovr'"
      ],
      "metadata": {
        "id": "LEixkIqWAKpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**roc_auc_ovr**<br>\n",
        "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
        "\n",
        "Note: this implementation can be used with binary, multiclass and multilabel classification, but some restrictions apply<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "7JEowOzacV6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In multi-label classification, the roc_auc_score function is extended by averaging over the labels  \n",
        "\n",
        "In this case, you should provide a y_score of shape (n_samples, n_classes). When using the probability estimates, one needs to select the probability of the class with the greater label for each output.<br>"
      ],
      "metadata": {
        "id": "7dIPBx0eco21"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyonzto8KW6O"
      },
      "source": [
        "# define model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring='roc_auc_ovr')\n",
        "\n",
        "# summarize performance\n",
        "print(('Mean ROC AUC: %.3f' % mean(scores)))\n",
        "print(\"Scores:\",scores)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}