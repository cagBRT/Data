{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Sampling 3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP9MVPwe6Wwua7iRgcEjJkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Data_Sampling_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://imbalanced-learn.org/dev/under_sampling.html#controlled-under-sampling\n"
      ],
      "metadata": {
        "id": "UBTle-0qhiM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo/images"
      ],
      "metadata": {
        "id": "f-hR0_8NeiO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "pvqS7zVAexGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Undersampling Techniques**"
      ],
      "metadata": {
        "id": "Qb_qWIHrcell"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "from imblearn.under_sampling import OneSidedSelection\n",
        "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour"
      ],
      "metadata": {
        "id": "TfcUWft8cj9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a dataset**"
      ],
      "metadata": {
        "id": "acO9aSkcdIWZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-2KfewyQ0Ai"
      },
      "source": [
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "        n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Undersample imbalanced dataset with NearMiss-1**<br>\n",
        "NearMiss-1 selects samples from the majority class for which the average distance to some nearest neighbours is the smallest. In the following example, we use a 3-NN to compute the average distance on 2 specific samples of the majority class. Therefore, in this case the point linked by the green-dashed line will be selected since the average distance is smaller."
      ],
      "metadata": {
        "id": "Dm6RAhD0dQxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[NearMiss](hhttps://imbalanced-learn.org/dev/under_sampling.html#controlled-under-sampling) adds some heuristic rules to select samples. NearMiss implements 3 different types of heuristic which can be selected with the parameter version:<br>\n"
      ],
      "metadata": {
        "id": "72HkBKsOdVQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"Screen Shot 2022-02-15 at 2.20.04 PM.png\" , width=640)"
      ],
      "metadata": {
        "id": "9b1P66sAeY-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of NearMiss-1 undersampling**<br>"
      ],
      "metadata": {
        "id": "KdEqs0uQdzOS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc6fR43hRAkr"
      },
      "source": [
        "undersample = NearMiss(version=1, n_neighbors=3) # transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of Undersampling with NearMiss-2**<br>\n",
        "NearMiss-2 selects samples from the majority class for which the average distance to the farthest neighbors is the smallest. With the same configuration as previously presented, the sample linked to the green-dashed line will be selected since its distance the 3 farthest neighbors is the smallest."
      ],
      "metadata": {
        "id": "vd0k-QBRftno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"Screen Shot 2022-02-15 at 2.27.39 PM.png\" , width=640)"
      ],
      "metadata": {
        "id": "zcp4doPxfz3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xqXgIffROKN"
      },
      "source": [
        "# define the undersampling method\n",
        "undersample = NearMiss(version=2, n_neighbors=3) # transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Undersampling with NearMiss-3**<br>\n",
        "NearMiss-3 can be divided into 2 steps. First, a nearest-neighbors is used to short-list samples from the majority class (i.e. correspond to the highlighted samples in the following plot). Then, the sample with the largest average distance to the k nearest-neighbors are selected."
      ],
      "metadata": {
        "id": "6MEnaw1lgoy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"Screen Shot 2022-02-15 at 2.33.33 PM.png\" , width=640)"
      ],
      "metadata": {
        "id": "e30pWigOha6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiUEsY3xRZO4"
      },
      "source": [
        "# Undersample imbalanced dataset with NearMiss-3\n",
        "undersample = NearMiss(version=3, n_neighbors_ver3=3) # transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Condensed Nearest Neighbor Undersampling**<br>\n",
        "[CondensedNearestNeighbour](https://imbalanced-learn.org/stable/under_sampling.html#condensed-nearest-neighbors) uses a 1 nearest neighbor rule to iteratively decide if a sample should be removed or not"
      ],
      "metadata": {
        "id": "r9EBcuDShrH4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRUIwY5FRjqH"
      },
      "source": [
        "# undersample and plot imbalanced dataset with the Condensed Nearest Neighbor Rule\n",
        "undersample = CondensedNearestNeighbour(n_neighbors=1) # transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CondensedNearestNeighbour is sensitive to noise and will add noisy samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "h3hDN61LibIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Sided Selection Undersampling**<br>\n",
        "OneSidedSelection will use TomekLinks to remove noisy samples."
      ],
      "metadata": {
        "id": "nahTdzxuie3q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C69yjEYTxcg"
      },
      "source": [
        "\n",
        "# undersample and plot imbalanced dataset with Tomek Links\n",
        "# define the undersampling method undersample = TomekLinks()\n",
        "# transform the dataset\n",
        "oss = OneSidedSelection(random_state=0)\n",
        "X, y = oss.fit_resample(X, y)\n",
        "# summarize the new class distribution counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edited Nearest Neighbor Undersampling**<br>\n",
        "EditedNearestNeighbours applies a nearest-neighbors algorithm and “edits” the dataset by removing samples which do not agree “enough” with their neighboorhood. For each sample in the class to be under-sampled, the nearest-neighbours are computed and if the selection criterion is not fulfilled, the sample is removed:"
      ],
      "metadata": {
        "id": "Mkrcv4tgjOYy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlqyJDrhUXZa"
      },
      "source": [
        "# undersample and plot imbalanced dataset with the Edited Nearest Neighbor rule\n",
        "undersample = EditedNearestNeighbours(n_neighbors=3) # transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSAiNJTWUjwQ"
      },
      "source": [
        "# undersample and plot imbalanced dataset with One-Sided Selection\n",
        "undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200) # transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assigment**<br>\n",
        "1. Change the weights of the classes, what is impact on the performance?"
      ],
      "metadata": {
        "id": "GMdODr-JkChQ"
      }
    }
  ]
}