{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced Dataset Example.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNe97V7MfiNFO77jrOtZj6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Imbalanced_Dataset_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qQA3UQ0PPZ0"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnTKZYhwPk5N"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "5xG1bCa9dbiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import isnan\n",
        "from numpy import asarray\n",
        "from numpy import polyfit\n",
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "b0Zt9WJ3mHry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "metadata": {
        "id": "5UmHL4PwoU9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYK0oHhHPXHW"
      },
      "source": [
        "filename = '/content/cloned-repo/survivalData.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the data**<br>\n",
        "\n",
        "Relevant Information: The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "\n",
        "Age of patient at time of operation (numerical)<br>\n",
        "\n",
        "Patient's year of operation (year - 1900, numerical)<br>\n",
        "\n",
        "Number of positive axillary nodes detected (numerical)<br>\n",
        "\n",
        "Survival status (class attribute)<br>\n",
        "\n",
        ">1 = the patient survived 5 years or longer<br>\n",
        "\n",
        ">2 = the patient died within 5 year<br>"
      ],
      "metadata": {
        "id": "nb3uZXJ9cFif"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AcirSMkPeg6"
      },
      "source": [
        "columns = ['age', 'year', 'nodes', 'class']\n",
        "dataframe = pd.read_csv(filename, header=None, names=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.columns"
      ],
      "metadata": {
        "id": "jL3qOPZxn8Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe.plot()"
      ],
      "metadata": {
        "id": "vXS5vhQFblEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['age'].value_counts()"
      ],
      "metadata": {
        "id": "9xZw6P_kpYds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['year'].value_counts()"
      ],
      "metadata": {
        "id": "Owh--y31ptn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['nodes'].value_counts()"
      ],
      "metadata": {
        "id": "OpPI7cKfpobY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf2Tj7sOQ526"
      },
      "source": [
        "report = dataframe.describe()\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRVfzzX9ROcz"
      },
      "source": [
        "dataframe.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Counter the labels for each class**"
      ],
      "metadata": {
        "id": "-swtGEwBqMmg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suzX3OVlRrpM"
      },
      "source": [
        "target = dataframe['class'].values\n",
        "counter = Counter(target)\n",
        "for k,v in counter.items():\n",
        "  per = v / len(target) * 100\n",
        "  print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = dataframe.values\n",
        "X = array[:,:3]\n",
        "Y = array[:,3]\n",
        "#validation_size = 0.30\n",
        "#seed = 10\n",
        "#X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n",
        "#test_size=validation_size, random_state=seed)"
      ],
      "metadata": {
        "id": "qxxQHJ0WcqG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test options and evaluation metric\n",
        "num_folds = 20\n",
        "#num_instances = len(X_train)\n",
        "seed = 10\n",
        "scoring = 'accuracy'"
      ],
      "metadata": {
        "id": "AMO9fISvdMJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = list()\n",
        "\tmodels.append(LogisticRegression())\n",
        "\tmodels.append(RidgeClassifier())\n",
        "\tmodels.append(SGDClassifier())\n",
        "\tmodels.append(PassiveAggressiveClassifier())\n",
        "\tmodels.append(KNeighborsClassifier())\n",
        "\tmodels.append(DecisionTreeClassifier())\n",
        "\tmodels.append(ExtraTreeClassifier())\n",
        "\tmodels.append(LinearSVC())\n",
        "\tmodels.append(SVC())\n",
        "\tmodels.append(GaussianNB())\n",
        "\tmodels.append(AdaBoostClassifier())\n",
        "\tmodels.append(BaggingClassifier())\n",
        "\tmodels.append(RandomForestClassifier())\n",
        "\tmodels.append(ExtraTreesClassifier())\n",
        "\tmodels.append(GaussianProcessClassifier())\n",
        "\tmodels.append(GradientBoostingClassifier())\n",
        "\tmodels.append(LinearDiscriminantAnalysis())\n",
        "\tmodels.append(QuadraticDiscriminantAnalysis())\n",
        "\treturn models"
      ],
      "metadata": {
        "id": "MfJNstcGmNrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model using a given test condition\n",
        "def evaluate_model(cv, model,X,y):\n",
        "\t# evaluate the model\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\t# return scores\n",
        "\treturn mean(scores)"
      ],
      "metadata": {
        "id": "qJ_bpJ5Xl-Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define test conditions\n",
        "ideal_cv = LeaveOneOut()\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# get the list of models to consider\n",
        "models = get_models()\n",
        "# collect results\n",
        "ideal_results, cv_results = list(), list()\n",
        "# evaluate each model\n",
        "for model in models:\n",
        "\t# evaluate model using each test condition\n",
        "\tcv_mean = evaluate_model(cv, model,X,Y)\n",
        "\tideal_mean = evaluate_model(ideal_cv, model,X,Y)\n",
        "\t# check for invalid results\n",
        "\tif isnan(cv_mean) or isnan(ideal_mean):\n",
        "\t\tcontinue\n",
        "\t# store results\n",
        "\tcv_results.append(cv_mean)\n",
        "\tideal_results.append(ideal_mean)\n",
        "\t# summarize progress\n",
        "\tprint('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))"
      ],
      "metadata": {
        "id": "JS6lQVaimChU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}