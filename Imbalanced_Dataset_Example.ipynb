{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced Dataset Example.ipynb",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNGjXCvgN9jowX80r7/eXpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Imbalanced_Dataset_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this notebook we look at a real imbalanced dataset, as opposed to synthetic data.**"
      ],
      "metadata": {
        "id": "YPJA5DLNsdYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compare various logistic regression models using cross validation - leave one out - to find the best model for this dataset."
      ],
      "metadata": {
        "id": "XewBzS9Esmk_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qQA3UQ0PPZ0"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnTKZYhwPk5N"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "5xG1bCa9dbiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import isnan\n",
        "from numpy import asarray\n",
        "from numpy import polyfit\n",
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "b0Zt9WJ3mHry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The logistic regression models we will compare**"
      ],
      "metadata": {
        "id": "fBr-XD7es5Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "metadata": {
        "id": "5UmHL4PwoU9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYK0oHhHPXHW"
      },
      "source": [
        "filename = '/content/cloned-repo/survivalData.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the data**<br>\n",
        "\n",
        "Relevant Information: The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "\n",
        "Age of patient at time of operation (numerical)<br>\n",
        "\n",
        "Patient's year of operation (year - 1900, numerical)<br>\n",
        "\n",
        "Number of positive axillary nodes detected (numerical)<br>\n",
        "\n",
        "Survival status (class attribute)<br>\n",
        "\n",
        ">1 = the patient survived 5 years or longer<br>\n",
        "\n",
        ">2 = the patient died within 5 year<br>"
      ],
      "metadata": {
        "id": "nb3uZXJ9cFif"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AcirSMkPeg6"
      },
      "source": [
        "columns = ['age', 'year', 'nodes', 'class']\n",
        "dataframe = pd.read_csv(filename, header=None, names=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.columns"
      ],
      "metadata": {
        "id": "jL3qOPZxn8Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['age'].value_counts()"
      ],
      "metadata": {
        "id": "9xZw6P_kpYds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['year'].value_counts()"
      ],
      "metadata": {
        "id": "Owh--y31ptn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['nodes'].value_counts()"
      ],
      "metadata": {
        "id": "OpPI7cKfpobY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf2Tj7sOQ526"
      },
      "source": [
        "report = dataframe.describe()\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRVfzzX9ROcz"
      },
      "source": [
        "dataframe.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count the labels for each class**"
      ],
      "metadata": {
        "id": "-swtGEwBqMmg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suzX3OVlRrpM"
      },
      "source": [
        "target = dataframe['class'].values\n",
        "counter = Counter(target)\n",
        "for k,v in counter.items():\n",
        "  per = v / len(target) * 100\n",
        "  print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = dataframe.values\n",
        "X = array[:,:3]\n",
        "Y = array[:,3]"
      ],
      "metadata": {
        "id": "qxxQHJ0WcqG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test options and evaluation metric\n",
        "num_folds = 20\n",
        "seed = 10\n",
        "scoring = 'accuracy'"
      ],
      "metadata": {
        "id": "AMO9fISvdMJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = list()\n",
        "\tmodels.append(LogisticRegression())\n",
        "\tmodels.append(RidgeClassifier())\n",
        "\tmodels.append(SGDClassifier())\n",
        "\tmodels.append(PassiveAggressiveClassifier())\n",
        "\tmodels.append(KNeighborsClassifier())\n",
        "\tmodels.append(DecisionTreeClassifier())\n",
        "\tmodels.append(ExtraTreeClassifier())\n",
        "\tmodels.append(LinearSVC())\n",
        "\tmodels.append(SVC())\n",
        "\tmodels.append(GaussianNB())\n",
        "\tmodels.append(AdaBoostClassifier())\n",
        "\tmodels.append(BaggingClassifier())\n",
        "\tmodels.append(RandomForestClassifier())\n",
        "\tmodels.append(ExtraTreesClassifier())\n",
        "\tmodels.append(GaussianProcessClassifier())\n",
        "\tmodels.append(GradientBoostingClassifier())\n",
        "\tmodels.append(LinearDiscriminantAnalysis())\n",
        "\tmodels.append(QuadraticDiscriminantAnalysis())\n",
        "\treturn models"
      ],
      "metadata": {
        "id": "MfJNstcGmNrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model using a given test condition\n",
        "def evaluate_model(cv, model,X,y):\n",
        "\t# evaluate the model\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\t# return scores\n",
        "\treturn mean(scores)"
      ],
      "metadata": {
        "id": "qJ_bpJ5Xl-Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define test conditions\n",
        "ideal_cv = LeaveOneOut()\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# get the list of models to consider\n",
        "models = get_models()\n",
        "# collect results\n",
        "ideal_results, cv_results = list(), list()\n",
        "# evaluate each model\n",
        "for model in models:\n",
        "\t# evaluate model using each test condition\n",
        "\tcv_mean = evaluate_model(cv, model,X,Y)\n",
        "\tideal_mean = evaluate_model(ideal_cv, model,X,Y)\n",
        "\t# check for invalid results\n",
        "\tif isnan(cv_mean) or isnan(ideal_mean):\n",
        "\t\tcontinue\n",
        "\t# store results\n",
        "\tcv_results.append(cv_mean)\n",
        "\tideal_results.append(ideal_mean)\n",
        "\t# summarize progress\n",
        "\tprint('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))"
      ],
      "metadata": {
        "id": "JS6lQVaimChU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What methods can we use to try and improve model performance?**"
      ],
      "metadata": {
        "id": "9uBdqytmsWtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binning**<br>\n",
        ">‘uniform’: All bins in each feature have identical widths.\n",
        "\n",
        ">‘quantile’: All bins in each feature have the same number of points.\n",
        "\n",
        ">‘kmeans’: Values in each bin have the same nearest center of a 1D k-means cluster.\n"
      ],
      "metadata": {
        "id": "ovpcFmtYt1Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "X = [[-2, 1, -4,   -1],\n",
        "     [-1, 2, -3, -0.5],\n",
        "     [ 0, 3, -2,  0.5],\n",
        "     [ 1, 4, -1,    2]]\n",
        "est = KBinsDiscretizer(\n",
        "    n_bins=3, encode='ordinal', strategy='uniform', subsample=None\n",
        ")\n",
        "est.fit(X)\n",
        "Xt = est.transform(X)\n",
        "Xt"
      ],
      "metadata": {
        "id": "dy9Spd05sE5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversampling**<br>\n",
        "https://imbalanced-learn.org/stable/over_sampling.html\n"
      ],
      "metadata": {
        "id": "7qoGcOzQuuVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
        "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
        "                           n_clusters_per_class=1,\n",
        "                           weights=[0.01, 0.05, 0.94],\n",
        "                           class_sep=0.8, random_state=0)\n",
        "\n",
        "print(sorted(Counter(y).items()))"
      ],
      "metadata": {
        "id": "CXki2Kw8us0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=0)\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "metadata": {
        "id": "BBRoBuTowPqr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}