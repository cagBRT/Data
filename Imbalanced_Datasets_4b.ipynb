{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced Datasets 4b.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNR1wZrY8slME33VIQiszzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Imbalanced_Datasets_4b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2UB02twFMVQ"
      },
      "source": [
        "# **Receiver Operation Characteristic (ROC)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fyXSpTfGHQw"
      },
      "source": [
        "While ROC Curve is a helpful diagnostic tool, it can be difficult to compare classifiers based on their curves. <br>\n",
        "Instead, the area under the curve can be calculated to give a single score for a classifier model across all threshold values. <br>\n",
        "This is called the ROC area under curve or ROC AUC or sometimes ROCAUC. <br>\n",
        "The score is a value between 0.0 and 1.0, with **1.0 indicating a perfect classifier**.<br>\n",
        "\n",
        "This single score can be used to compare binary classifier models directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ULlgKtOq6h"
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"image/\"+str(num)+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sz0wfE3Onve"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWIe6d5uOz6N"
      },
      "source": [
        "Image(\"images/AUC\"+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1q1inmdPKIG"
      },
      "source": [
        "The ROC AUC should be used with caution. <br>\n",
        "\n",
        "For imbalanced classification with a severe skew and few examples of the minority class, the ROC AUC can be misleading. <br>\n",
        "\n",
        "This is because a small number of correct or incorrect predictions can result in a large change in the ROC Curve or ROC AUC score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4UHG7KkNC8R"
      },
      "source": [
        "# example of a roc auc for a predictive model\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from numpy import where\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "Luam5HXYNQT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_2dQLVxN1oK"
      },
      "source": [
        "**Create a dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f8cqljLNFag"
      },
      "source": [
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbnWVNkFN7hr"
      },
      "source": [
        "**Plot the data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H30awHE-NkCm"
      },
      "source": [
        "for class_value in range(2):\n",
        "  # get row indexes for samples with this class\n",
        "  row_ix = where(y == class_value)\n",
        "    # create scatter of these samples\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "  # show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da7c9UhTOOHv"
      },
      "source": [
        "**Create a Dummy classifier model and train it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZltSXlNJiG"
      },
      "source": [
        "# no skill model, stratified random class predictions\n",
        "model = DummyClassifier(strategy='stratified')\n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "pos_probs = yhat[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3R5cBvNOWXd"
      },
      "source": [
        "**Calculate the ROC AUC score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6YQa5n-OHaS"
      },
      "source": [
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, pos_probs)\n",
        "print('No Skill ROC AUC %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVPCD1iKOb93"
      },
      "source": [
        "**Create and train a logistic regression model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xvgidpWMmJh"
      },
      "source": [
        "# skilled model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "pos_probs = yhat[:, 1]\n",
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, pos_probs)\n",
        "print('Logistic ROC AUC %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "Example of classification model use:\n",
        "    \n",
        ">  KNeighborsClassifier(3),<br>\n",
        "  SVC(kernel=\"linear\", C=0.025, random_state=42, probability=True),<br>\n",
        "  SVC(gamma=2, C=1, random_state=42, probability=True),<br>\n",
        "  GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),<br>\n",
        "  DecisionTreeClassifier(max_depth=5, random_state=42),<br>\n",
        "  RandomForestClassifier(\n",
        "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
        "  ),<br>\n",
        "  MLPClassifier(alpha=1, max_iter=1000, random_state=42),<br>\n",
        "  AdaBoostClassifier(random_state=42),<br>\n",
        "  GaussianNB(), <br>\n",
        "  QuadraticDiscriminantAnalysis(),<br>"
      ],
      "metadata": {
        "id": "rGdobMsANdKk"
      }
    }
  ]
}