{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMP85jlNcXKEpnnkfQww2mJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Thresholds_for_Imbalanced_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to tune the optimal threshold when converting probabilities to crisp class labels for imbalanced classification"
      ],
      "metadata": {
        "id": "uCwh21HrOcDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many machine learning algorithms are capable of predicting a probability or scoring of class membership, and this must be interpreted before it can be mapped to a class label. <br>\n",
        "\n",
        "This is achieved by using a threshold, such as 0.5, where all values equal or greater than the threshold are mapped to one class and all other values are mapped to another class."
      ],
      "metadata": {
        "id": "yXUpDVeqOHmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For those classification problems that have a severe class imbalance the default threshold can result in poor performance.\n",
        "\n",
        "As such, a simple and straightforward approach to improving the performance of a classifier that predicts probabilities on an imbalanced classification problem is to tune the threshold used to map probabilities to class labels."
      ],
      "metadata": {
        "id": "JBQUmKRzOQPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, such as when using ROC Curves and Precision-Recall Curves, **the best or optimal threshold for the classifier can be calculated directly**.\n",
        "\n",
        "In other cases, it is possible to use a grid search to tune the threshold and locate the optimal value."
      ],
      "metadata": {
        "id": "68VRN2xJOW-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many techniques that may be used to address an imbalanced classification problem, such as resampling the training dataset and developing customized version of machine learning algorithms.\n",
        "\n",
        "**The simplest approach to handle a severe class imbalance is to change the decision threshold.** <br>\n",
        "Although simple and very effective, this technique is often overlooked by practitioners and research academics alike as was noted by Foster Provost in his 2000 article titled “Machine Learning from Imbalanced Data Sets.”"
      ],
      "metadata": {
        "id": "QczNTGLtPJDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries"
      ],
      "metadata": {
        "id": "48bCEgqvy8_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# roc curve for logistic regression model\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "metadata": {
        "id": "ZaBKjQ_1QYDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import sqrt\n",
        "from numpy import argmax\n",
        "from numpy import arange\n",
        "from numpy import argmax"
      ],
      "metadata": {
        "id": "UordtR2qRGju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the datset"
      ],
      "metadata": {
        "id": "wbxVAmQwzAf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        " n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)"
      ],
      "metadata": {
        "id": "KBI3_nDzQjtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and train the model"
      ],
      "metadata": {
        "id": "PzFduz-zzFFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fogihCu4N-4O"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "# predict probabilities\n",
        "yhat = model.predict_proba(testX)\n",
        "# keep probabilities for the positive outcome only\n",
        "yhat = yhat[:, 1]\n",
        "\n",
        "# calculate roc curves\n",
        "fpr, tpr, thresholds = roc_curve(testy, yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the curves"
      ],
      "metadata": {
        "id": "XTNPmbvvzNbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "pBV-heNNQt9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Locate the optimal threshold and report this threshold and the G-Mean score."
      ],
      "metadata": {
        "id": "J5AZTBTJRT5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n"
      ],
      "metadata": {
        "id": "N4zmq2hZRBmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "pyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "wPMqiEY8zbUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate the optimal statistic directly."
      ],
      "metadata": {
        "id": "afeWgpYtRhNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(testy, yhat)\n",
        "# get the best threshold\n",
        "J = tpr - fpr\n",
        "ix = argmax(J)\n",
        "best_thresh = thresholds[ix]\n",
        "print('Best Threshold=%f' % (best_thresh))"
      ],
      "metadata": {
        "id": "zIGQFfEIRZGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Optimal Threshold for Precision-Recall Curve"
      ],
      "metadata": {
        "id": "-AVbd9qHj7fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate pr-curve\n",
        "precision, recall, thresholds = precision_recall_curve(testy, yhat)\n",
        "# plot the roc curve for the model\n",
        "no_skill = len(testy[testy==1]) / len(testy)\n",
        "pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "27J2y30zj78a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the optimal point"
      ],
      "metadata": {
        "id": "-oZlyNc3kW_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = yhat[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(testy, yhat)\n",
        "# convert to f score\n",
        "fscore = (2 * precision * recall) / (precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n"
      ],
      "metadata": {
        "id": "rLOSAjIEkU2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "no_skill = len(testy[testy==1]) / len(testy)\n",
        "pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
        "pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "OT0Wf9Iiz1IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal Threshold Tuning"
      ],
      "metadata": {
        "id": "kd8QTMu7keMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, we simply have a model and we wish to know the best threshold directly.\n",
        "\n",
        "In this case, we can define a set of thresholds and then evaluate predicted probabilities under each in order to find and select the optimal threshold.\n",
        "\n"
      ],
      "metadata": {
        "id": "MzzYnarukhyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit a logistic regression model on our synthetic classification problem, then predict class labels and evaluate them using the F-Measure, which is the harmonic mean of precision and recall.\n",
        "\n",
        "This will use the default threshold of 0.5 when interpreting the probabilities predicted by the logistic regression model."
      ],
      "metadata": {
        "id": "ueC-cUe9kmpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "yhat = model.predict(testX)\n",
        "# evaluate the model\n",
        "score = f1_score(testy, yhat)\n",
        "print('F-Score: %.5f' % score)"
      ],
      "metadata": {
        "id": "BI9pQMdrkek_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the same model on the same dataset and instead of predicting class labels directly, we can predict probabilities."
      ],
      "metadata": {
        "id": "XPtiqL1KlHVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply threshold to positive probabilities to create labels\n",
        "def to_labels(pos_probs, threshold):\n",
        " return (pos_probs >= threshold).astype('int')\n",
        "\n",
        "\n",
        "yhat = model.predict_proba(testX)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs = yhat[:, 1]\n",
        "# define thresholds\n",
        "thresholds = arange(0, 1, 0.001)\n",
        "# evaluate each threshold\n",
        "scores = [f1_score(testy, to_labels(probs, t)) for t in thresholds]\n",
        "# get best threshold\n",
        "ix = argmax(scores)\n",
        "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))"
      ],
      "metadata": {
        "id": "tJCLvC_0lHrU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}