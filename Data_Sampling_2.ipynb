{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Sampling 2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNUdgDPOkEqzYltfBTcPFnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Data_Sampling_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HRLEXHtGVAd"
      },
      "source": [
        "# **Sythetic Minority Oversampling Technique (SMOTE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4kS97gJGeBw"
      },
      "source": [
        "As we saw in Data Sampling 1, oversampling duplicates data from the minority class until the classes are of similiar size. \n",
        "\n",
        "SMOTE sythsizes new data from existing examples. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQS3y2tlHC2Q"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnOUB0gxHDFj"
      },
      "source": [
        "# Generate and plot a synthetic imbalanced classification dataset\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtSi_m_vHKpW"
      },
      "source": [
        "Create an imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "artrDv6QHM5N"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn5eDzqxumTM"
      },
      "source": [
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iAlkfVYHT5M"
      },
      "source": [
        "**Use SMOTE to augment the minority class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ymB831hI9do"
      },
      "source": [
        "SMOTE works by:<br>\n",
        "1. select a random example from the minority class that are close in the feature space\n",
        "2. Find the k nearest neighbors of the selected example \n",
        "2. Draw a line between the example and its nearest neighbor in the feature space  \n",
        "3. Draw a new sample at a point along that line.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlA-jvKaHj1f"
      },
      "source": [
        "**Import the SMOTE library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GGtpAchHgXO"
      },
      "source": [
        "# Oversample and plot imbalanced dataset with SMOTE\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ15MGoPICx7"
      },
      "source": [
        "**Transform the dataset using SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJjuMS97KPgw"
      },
      "source": [
        "# use SMOTE to transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA9Hvrt9KUfX"
      },
      "source": [
        "# summarize the new class distribution \n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpNg-1YYu2X5"
      },
      "source": [
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSC10tDDJnmB"
      },
      "source": [
        "**A downside of SMOTE** is that synthetic examples are created without considering the majority class, which can ressult in ambiguous examples when there is a strong overlap for the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNxfUEpYIe96"
      },
      "source": [
        "**Assignment #1**<br>\n",
        "Modify the number of datapoints in the dataset. \n",
        "What happens when the dataset is less than 1000 examples?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6cHgXgZI0TV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMk0MW6Su_P8"
      },
      "source": [
        "# decision tree evaluated on imbalanced dataset\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# define model\n",
        "model = DecisionTreeClassifier()\n",
        "# evaluate pipeline\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
        "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) \n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IToaTYgovKc1"
      },
      "source": [
        "# decision tree evaluated on imbalanced dataset with SMOTE oversampling\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# define pipeline\n",
        "steps = [('over', SMOTE()), ('model', DecisionTreeClassifier())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# evaluate pipeline\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) \n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok21tqm8vRqY"
      },
      "source": [
        "# grid search k value for SMOTE oversampling for imbalanced classification\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# values to evaluate\n",
        "k_values = [1, 2, 3, 4, 5, 6, 7] \n",
        "for k in k_values:\n",
        "  # define pipeline\n",
        "  model = DecisionTreeClassifier()\n",
        "  over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
        "  pipeline = Pipeline(steps=[('over', over), ('model', model)])\n",
        "  # evaluate pipeline\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) \n",
        "  score = mean(scores)\n",
        "  print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mam4uSBvfj3"
      },
      "source": [
        "# borderline-SMOTE for imbalanced dataset\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification \n",
        "from imblearn.over_sampling import BorderlineSMOTE \n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# transform the dataset\n",
        "oversample = BorderlineSMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhFdPS4jvv6x"
      },
      "source": [
        "# borderline-SMOTE with SVM for imbalanced dataset\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# transform the dataset\n",
        "oversample = SVMSMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUKRyHjv4vg"
      },
      "source": [
        "# Oversample and plot imbalanced dataset with ADASYN\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# transform the dataset\n",
        "oversample = ADASYN()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label \n",
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label)) \n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}