{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced Datasets 4c.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN6ExyfRSt5MoIzUhvFW47g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Imbalanced_Datasets_4c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNKRT8Tldx4"
      },
      "source": [
        "ROC Curves and Precision-Recall Curves provide a diagnostic tool for binary classification models.<br>\n",
        "\n",
        "ROC AUC and Precision-Recall AUC provide scores that summarize the curves and can be used to compare classifiers.<br>\n",
        "\n",
        "ROC Curves and ROC AUC can be optimistic on severely imbalanced classification problems with few samples of the minority class.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myswek72SZtz"
      },
      "source": [
        "# **Precision-Recall Curves**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9vl_IV5TnC-"
      },
      "source": [
        "**Precision = TruePositive /( TruePositive + FalsePositive)**<br>\n",
        "\n",
        "A  value between 0.0 for no precision and 1.0 for full or perfect precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgsxF16Tv0d"
      },
      "source": [
        "**Recall = TruePositive / (TruePositive + FalseNegative)**<br>\n",
        "\n",
        "A value between 0.0 for no recall and 1.0 for full or perfect recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGUhWPlFQPZZ"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW4LT6PEP54k"
      },
      "source": [
        "# example of a precision-recall curve for a predictive model\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "from sklearn.metrics import auc\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVUwrTuQVY4"
      },
      "source": [
        "**Create a dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9yhL7qPP949"
      },
      "source": [
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=10000, n_classes=2, random_state=1)\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2) # fit a model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQ7OewhQhwb"
      },
      "source": [
        "for class_value in range(2):\n",
        "  # get row indexes for samples with this class\n",
        "  row_ix = where(y == class_value)\n",
        "    # create scatter of these samples\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "  # show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUsE9bCgQxm4"
      },
      "source": [
        "**Create and train a logistic regression model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9zFtmOFPlXn"
      },
      "source": [
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "# predict probabilities\n",
        "yhat = model.predict_proba(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S_zUikSQFNs"
      },
      "source": [
        "# retrieve just the probabilities for the positive class\n",
        "pos_probs = yhat[:, 1]\n",
        "# calculate the no skill line as the proportion of the positive class\n",
        "no_skill = len(y[y==1]) / len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdVbkKDHRbUb"
      },
      "source": [
        "# calculate model precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(testy, pos_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBJhgFcsRG8y"
      },
      "source": [
        "The Precision-Recall Curve for the Logistic Regression model is shown (orange).\n",
        "A random or baseline classifier is shown as a horizontal line (blue with dashes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y826E3C4S7hE"
      },
      "source": [
        "A model with perfect skill is depicted as a point at a coordinate of (1,1). <br>\n",
        "\n",
        "A skillful model is represented by a curve that bows towards a coordinate of (1,1). <br>\n",
        "\n",
        "A no-skill classifier will be a horizontal line on the plot with a precision that is proportional to the number of positive examples in the dataset.<br>\n",
        "\n",
        "For a balanced dataset this will be 0.5.<br>\n",
        "\n",
        "**The focus of the PR curve on the minority class makes it an effective diagnostic for imbalanced binary classification models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyK68vroSRnX"
      },
      "source": [
        "Precision-recall curves (PR curves) are recommended for highly skewed domains\n",
        "where ROC curves may provide an excessively optimistic view of the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRryCK1zPxc9"
      },
      "source": [
        "# plot the no skill precision-recall curve\n",
        "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "# plot the model precision-recall curve\n",
        "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_WkAH2RVlzv"
      },
      "source": [
        "# **ROC and PR CCurves with Severe Imbalanced Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhqpF7nOWIri"
      },
      "source": [
        "**Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlR7eaAXVyel"
      },
      "source": [
        "# create an imbalanced dataset\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwy8GkhcWMgg"
      },
      "source": [
        "**Create the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2seMz-PmV4Gm"
      },
      "source": [
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01],\n",
        "random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s4oMJOLVyjO"
      },
      "source": [
        "# split into train/test sets with same class ratio\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
        "# summarize dataset\n",
        "print('Dataset: Class0=%d, Class1=%d' % (len(y[y==0]), len(y[y==1])))\n",
        "print('Train: Class0=%d, Class1=%d' % (len(trainy[trainy==0]), len(trainy[trainy==1]))) \n",
        "print('Test: Class0=%d, Class1=%d' % (len(testy[testy==0]), len(testy[testy==1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hr52onGWhmt"
      },
      "source": [
        "# plot no skill and model roc curves\n",
        "def plot_roc_curve(test_y, naive_probs, model_probs):\n",
        "# plot naive skill roc curve\n",
        "  fpr, tpr, _ = roc_curve(test_y, naive_probs) \n",
        "  pyplot.plot(fpr, tpr, linestyle='--', label='No Skill') # plot model roc curve\n",
        "  fpr, tpr, _ = roc_curve(test_y, model_probs) \n",
        "  pyplot.plot(fpr, tpr, marker='.', label='Logistic') # axis labels\n",
        "  pyplot.xlabel('False Positive Rate') \n",
        "  pyplot.ylabel('True Positive Rate')\n",
        "  # show the legend\n",
        "  pyplot.legend()\n",
        "  # show the plot\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fugqwqhWHa"
      },
      "source": [
        "**Create and train a model with no skill**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkm19TCbWzEq"
      },
      "source": [
        "# no skill model, stratified random class predictions\n",
        "model = DummyClassifier(strategy='stratified') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "naive_probs = yhat[:, 1]\n",
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, naive_probs) \n",
        "print('No Skill ROC AUC %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzC4L0XlhWOp"
      },
      "source": [
        "**Create and train a logistic regression model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I5zatDVW34S"
      },
      "source": [
        "# skilled model\n",
        "model = LogisticRegression(solver='lbfgs') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX) \n",
        "model_probs = yhat[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9PikUyvhu6Z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtIV7iohhu81"
      },
      "source": [
        "**Plot the ROC Curves**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im55JltYW_VA"
      },
      "source": [
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, model_probs) \n",
        "print('Logistic ROC AUC %.3f' % roc_auc)\n",
        "# plot roc curves\n",
        "plot_roc_curve(testy, naive_probs, model_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eas8fOmdiPY1"
      },
      "source": [
        "def plot_pr_curve(test_y, model_probs):\n",
        "  # calculate the no skill line as the proportion of the positive class \n",
        "  no_skill = len(test_y[test_y==1]) / len(test_y)\n",
        "  # plot the no skill precision-recall curve\n",
        "  pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill') # plot model precision-recall curve\n",
        "  precision, recall, _ = precision_recall_curve(testy, model_probs)\n",
        "  pyplot.plot(recall, precision, marker='.', label='Logistic') # axis labels\n",
        "  pyplot.xlabel('Recall')\n",
        "  pyplot.ylabel('Precision')\n",
        "    # show the legend\n",
        "  pyplot.legend()\n",
        "    # show the plot\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbDdJLXCiqmG"
      },
      "source": [
        "precision, recall, _ = precision_recall_curve(testy, naive_probs)\n",
        "auc_score = auc(recall, precision)\n",
        "print('No Skill PR AUC: %.3f' % auc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1NsGUzBievv"
      },
      "source": [
        "# calculate the precision-recall auc\n",
        "precision, recall, _ = precision_recall_curve(testy, model_probs) \n",
        "auc_score = auc(recall, precision)\n",
        "print('Logistic PR AUC: %.3f' % auc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPUIloI-i9VF"
      },
      "source": [
        "The horizontal line of the no skill classifier is expected and in this case the zig-zag line of the logistic regression curve close to the no skill line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd2dwi5th-hD"
      },
      "source": [
        "# plot precision-recall curves\n",
        "plot_pr_curve(testy, model_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE-aUk2mjlbA"
      },
      "source": [
        "To explain why the ROC and PR curves tell a different story, recall that the PR curve focuses on the minority class, whereas the ROC curve covers both classes. If we use a threshold of 0.5 and use the logistic regression model to make a prediction for all examples in the test set, we see that it predicts class 0 or the majority class in all cases. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A6D6sY-k99r"
      },
      "source": [
        "# predict probabilities\n",
        "yhat = model.predict_proba(testX)\n",
        "# retrieve just the probabilities for the positive class\n",
        "pos_probs = yhat[:, 1]\n",
        "# predict class labels\n",
        "yhat = model.predict(testX)\n",
        "# summarize the distribution of class labels\n",
        "print(Counter(yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVwYuCpelLn1"
      },
      "source": [
        "# create a histogram of the predicted probabilities \n",
        "pyplot.hist(pos_probs, bins=100) \n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}