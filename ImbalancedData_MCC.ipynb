{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM8JgG0/F+frhZ4abMoGGKK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/ImbalancedData_MCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matthews Correlation Coefficient(MCC)"
      ],
      "metadata": {
        "id": "yJO0p_sBd7Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matthew's correlation coefficient, also abbreviated as MCC was invented by Brian Matthews in 1975.<br>\n",
        "\n",
        "MCC is a statistical tool used for model evaluation. Its job is to gauge or measure the difference between the predicted values and actual values"
      ],
      "metadata": {
        "id": "nJaWvod-d8rH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66kcE_OWWca5"
      },
      "outputs": [],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import unique\n",
        "from numpy import where\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_blobs\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "PUGGtFu_ZELk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "kt8PVHQbZTfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ],
      "metadata": {
        "id": "Y1vx6hdkZziv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "t746D4E6ZXst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For measuring model performance there are four metrics in addition to ROC curves.<br>\n",
        "Each of the four can someimes be misleading. <br>\n",
        "Which is why we will discuss MCC"
      ],
      "metadata": {
        "id": "h_qRNgJ2_xqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a small example"
      ],
      "metadata": {
        "id": "YLy7UJ0OCZXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"images/DogsCats1.png\")"
      ],
      "metadata": {
        "id": "A4DGxIqyEDU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dataset: 21 dogs, 3 cats**<br>\n",
        "Precision is the proportion of true positives out of all detected positives, or simply TP/(TP+FP).<br>\n",
        "\n",
        "In this case, dog photos are the positive class, and 18 out of 21 photos that were classified as dogs actually contain dogs.<br>\n",
        "\n",
        "**The precision is 18/21=86%.** <br>\n",
        "The recall is the number of true positives that are correctly classified (TP/(TP+FN)). From the above matrix it is easy to see that there are 20 true positives, and 18 of them are successfully detected.<br>\n",
        "**Recall is 18/(18+2), or 90%.**<br>\n",
        "\n",
        "**The F1 score is 88%**"
      ],
      "metadata": {
        "id": "-xp56a9cGoWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision and recall consider one class , the positive class, to be the class we are interested in. <br>\n",
        "\n",
        "They use only three of the values in the confusion matrix: TP, FP, and FN. The 4th value — TN — is not used in these metrics.<br>\n",
        "\n",
        "\n",
        "You can put any value in the TN cell —0, 100, infinity — and the precision, recall and F1-score will not change.\n",
        "\n"
      ],
      "metadata": {
        "id": "rdvDJmpbH6Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"images/DogsCats2.png\")"
      ],
      "metadata": {
        "id": "OJYfwqeAIsHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, flip the confusion matrix. Let’s consider “cat” to be the positive class, i.e., the one we are interested in.<br>\n",
        "The dataset is still 21 dogs, 3 cats<br>\n",
        "\n",
        "**Precision is 33%**,<br>\n",
        "**Recall 25%**, <br>\n",
        "**F1-score is 29%**<br>\n",
        "\n",
        "There are 24 datapoints, and 19 were correctly classified.<br>\n",
        "Accuracy for dogs: 90%<br>\n",
        "Accuracy for cats: 25%\n",
        "\n"
      ],
      "metadata": {
        "id": "mbkzbx6mJ-xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The change the metrics occurs because the classes are imbalanced. Depending which one is the positive class in an imbalanced dataset can greatly change the metrics.**"
      ],
      "metadata": {
        "id": "2s-RY2ovKFIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matthews Correlation Coefficient**\n",
        "*For binary classification, there is another solution:* <BR>\n",
        "- treat the true class and the predicted class as two (binary) variables,\n",
        "- compute their correlation coefficient. <br>\n",
        "\n",
        "**The higher the correlation between true and predicted values, the better the prediction.** <br>\n",
        "\n",
        "This is the phi-coefficient (φ), rechristened Matthews Correlation Coefficient (MCC) when applied to classifiers."
      ],
      "metadata": {
        "id": "Y8XqkrXXWdCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"images/MCCEQUATION.png\" , width=640)"
      ],
      "metadata": {
        "id": "1pKMg7rPM2Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MCC value is always between -1 and 1, with 0 meaning that the classifier is no better than a random flip of a fair coin**. <br>\n",
        "\n",
        "**MCC is also perfectly symmetric**, so no class is more important than the other; if you switch the positive and negative, you’ll still get the same value.\n",
        "\n",
        "**MCC takes into account all four values in the confusion matrix**, and a high value (close to 1) means that both classes are predicted well, even if one class is disproportionately under- (or over-) represented."
      ],
      "metadata": {
        "id": "ccov4SaDWh2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A larger dataset example"
      ],
      "metadata": {
        "id": "N0mIkHHrNmWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create an impbalanced dataset**"
      ],
      "metadata": {
        "id": "StYTn9Tfu-fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataset\n",
        "X1, y1 = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1,\n",
        "                           weights=[0.99,0.01], flip_y=0, random_state=4)\n",
        "\n",
        "X2, y2 = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1,\n",
        "                           weights=[0.01,0.99], flip_y=0, random_state=4)"
      ],
      "metadata": {
        "id": "YttM91oLZg3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize class distribution\n",
        "counter = Counter(y1)\n",
        "print(counter)\n",
        "print(counter.items())\n",
        "print(counter.keys())"
      ],
      "metadata": {
        "id": "dWyGlZEyZmfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize class distribution\n",
        "counter = Counter(y2)\n",
        "print(counter)\n",
        "print(counter.items())\n",
        "print(counter.keys())"
      ],
      "metadata": {
        "id": "6w_4HbEzwJWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot of examples by class label\n",
        "for label,  _ in counter.items():\n",
        "  row_ix = where(y1 == label)[0]\n",
        "  pyplot.scatter(X1[row_ix, 0], X1[row_ix, 1], label=str(label))\n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "Ux8ihd_iZpF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot of examples by class label\n",
        "for label,  _ in counter.items():\n",
        "  row_ix = where(y2 == label)[0]\n",
        "  pyplot.scatter(X2[row_ix, 0], X2[row_ix, 1], label=str(label))\n",
        "  pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "PE5XdeSywUCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data into train and test sets**"
      ],
      "metadata": {
        "id": "Q3e_f78hvFOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
        "    X1, y1, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "0wj5xmJSZr_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "iX5ymahewhUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the model**"
      ],
      "metadata": {
        "id": "wtkf9GirvJk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model using repeated k-fold cross-validation\n",
        "def evaluate_model(X, y, model, X_train, y_train):\n",
        "  # define the evaluation procedure\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  # evaluate the model on the dataset\n",
        "  scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1) # return scores from each fold and each repeat\n",
        "  return scores"
      ],
      "metadata": {
        "id": "8fUZsB1uZ5sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model1 = LogisticRegression(solver='lbfgs')\n",
        "scores1 = evaluate_model(X1_test, y1_test, model1, X1_train, y1_train)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.2f%%' % (mean(scores1) * 100))"
      ],
      "metadata": {
        "id": "stp5pRs6Z8GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model2 = LogisticRegression(solver='lbfgs')\n",
        "scores2 = evaluate_model(X2_test, y2_test, model2, X2_train, y2_train)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.2f%%' % (mean(scores2) * 100))"
      ],
      "metadata": {
        "id": "GBh_CcdbwqZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "tgVtS9NCvRh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X1_train, y1_train)\n",
        "y_pred1=model1.predict(X1_test)\n",
        "pos_probs1 = y_pred1"
      ],
      "metadata": {
        "id": "uE2fvJKyw1b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X2_train, y2_train)\n",
        "y_pred2=model2.predict(X2_test)\n",
        "pos_probs2 = y_pred2"
      ],
      "metadata": {
        "id": "I_KBE1ynZ_dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calcuate the metrics for the model**"
      ],
      "metadata": {
        "id": "dDfi85R4vYP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion1 = confusion_matrix(y1_test, y_pred1)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion1)"
      ],
      "metadata": {
        "id": "XDVLERlVvVj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion2 = confusion_matrix(y2_test, y_pred2)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion2)"
      ],
      "metadata": {
        "id": "blW67uPexBbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate roc auc\n",
        "roc_auc1 = roc_auc_score(y1_test, pos_probs1)\n",
        "print('ROC AUC %.3f' % roc_auc1)"
      ],
      "metadata": {
        "id": "HJs-Wk1hboXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate roc auc\n",
        "roc_auc2 = roc_auc_score(y2_test, pos_probs2)\n",
        "print('ROC AUC %.3f' % roc_auc1)"
      ],
      "metadata": {
        "id": "m6u2dJ5TxL0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot no skill roc curve\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n",
        "# calculate roc curve for model\n",
        "fpr, tpr, _ = roc_curve(y1_test, pos_probs1)\n",
        "# plot model roc curve\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "HOKoCvZGa0M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot no skill roc curve\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n",
        "# calculate roc curve for model\n",
        "fpr, tpr, _ = roc_curve(y2_test, pos_probs2)\n",
        "# plot model roc curve\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "ljAZG4G8xT3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"f1 for dataset1:\", f1_score(y1_test, y_pred1, average='macro'))\n",
        "print(\"f2 for dataset2:\", f1_score(y2_test, y_pred2, average='macro'))"
      ],
      "metadata": {
        "id": "-sRFaxuFcO9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dataset 1:\",f1_score(y1_test, y_pred1, average='micro'))\n",
        "print(\"dataset 2:\",f1_score(y2_test, y_pred2, average='micro'))"
      ],
      "metadata": {
        "id": "C6fo8kKOcTaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dataset 1:\",f1_score(y1_test, y_pred1, average='weighted'))\n",
        "print(\"dataset 2:\",f1_score(y2_test, y_pred2, average='weighted'))"
      ],
      "metadata": {
        "id": "-ocoy_CIcW_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['class 0', 'class 1']"
      ],
      "metadata": {
        "id": "BQ53tTXIdI7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y1_test, y_pred1, target_names=target_names))"
      ],
      "metadata": {
        "id": "db4H4n7gdD2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y2_test, y_pred2, target_names=target_names))"
      ],
      "metadata": {
        "id": "kltJ-nt7yIlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MCC 1:\",matthews_corrcoef(y1_test,y_pred1))\n",
        "print(\"MCC 2:\",matthews_corrcoef(y2_test,y_pred2))"
      ],
      "metadata": {
        "id": "8pK41MIcb2m8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}