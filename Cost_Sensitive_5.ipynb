{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cost Sensitive 5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMOn6W/BJxxfvuSgh023sA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Cost_Sensitive_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TergmmetXZ03"
      },
      "source": [
        "# **Cost Sensitive DNNs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDihhbHZXoNr"
      },
      "source": [
        "Deep neural networks operate on the assumption that all classes are balanced. <br>\n",
        "To use DNNs with imbalanced datasets we can use backpropagation to weight exampless from the minority classs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR-tldkSYU2t"
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmRnlG9JYbwo"
      },
      "source": [
        "**Create an imbalanced dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCXTGlyZYZvw"
      },
      "source": [
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=4)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10pqTpMPbPyY"
      },
      "source": [
        "for label, _ in counter.items():\n",
        "  row_ix = where(y == label)[0]\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vrt4ZXIcaQru"
      },
      "source": [
        "**Define functions for preparing the data and defining the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvQ3xbFbaP69"
      },
      "source": [
        "# prepare train and test dataset\n",
        "def prepare_data():\n",
        "    # split into train and test\n",
        "  n_train = 5000\n",
        "  trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "  trainy, testy = y[:n_train], y[n_train:]\n",
        "  return trainX, trainy, testX, testy\n",
        "# define the neural network model\n",
        "\n",
        "def define_model(n_input):\n",
        "# define model\n",
        "  model = Sequential()\n",
        "  # define first hidden layer and visible layer\n",
        "  model.add(Dense(10, input_dim=n_input, activation='relu',kernel_initializer='he_uniform'))\n",
        "  # define output layer\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # define loss and optimizer\n",
        "  model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KULYIzvbaajC"
      },
      "source": [
        "**Split the data into training and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KXX-GYcaZzq"
      },
      "source": [
        "trainX, trainy, testX, testy = prepare_data()\n",
        "# define the model\n",
        "n_input = trainX.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOzKOt2LajaR"
      },
      "source": [
        "Create and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oFWc2hbboyj"
      },
      "source": [
        "model = define_model(n_input)\n",
        "# fit model\n",
        "model.fit(trainX, trainy, epochs=100, verbose=0)\n",
        "# make predictions on the test dataset\n",
        "yhat = model.predict(testX)\n",
        "# evaluate the ROC AUC of the predictions\n",
        "score = roc_auc_score(testy, yhat)\n",
        "print('ROC AUC: %.3f' % score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0UUtpjeanxa"
      },
      "source": [
        "# **Train the model with weighted classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULyNmK3kbFOf"
      },
      "source": [
        "The performance of the model improves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5RGxB7YcjiY"
      },
      "source": [
        "weights = {0:1, 1:100} #small weight is for the majority class\n",
        "history = model.fit(trainX, trainy, class_weight=weights, epochs=100, verbose=0) # evaluate model\n",
        "yhat_weight = model.predict(testX)\n",
        "score_weight = roc_auc_score(testy, yhat_weight)\n",
        "print('ROC AUC: %.3f' % score_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXupSIQxbKp5"
      },
      "source": [
        "**Assignment**<br>\n",
        "Modify the dataset:<br>\n",
        "- change the size\n",
        "- change the number of features\n",
        "-change the class ratio <br>\n",
        "\n",
        "Note the changes in performance between the two methods"
      ]
    }
  ]
}