{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cost Sensitive 1b.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMuGfQLxsG3KwvItpHjGdRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Cost_Sensitive_1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8tSjCKiuBjS"
      },
      "source": [
        "## **Applying cost sensitivity to a dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG7dEqqRtWu_"
      },
      "source": [
        "Number of Instances: 214\n",
        "\n",
        "Number of Attributes: 10 (including an Id#) plus the class attribute<br>\n",
        "   -- all attributes are continuously valued<br>\n",
        "\n",
        " Attribute Information:<br>\n",
        "   1. Id number: 1 to 214\n",
        "   2. RI: refractive index\n",
        "   3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
        "   4. Mg: Magnesium\n",
        "   5. Al: Aluminum\n",
        "   6. Si: Silicon\n",
        "   7. K: Potassium\n",
        "   8. Ca: Calcium\n",
        "   9. Ba: Barium<br>\n",
        "   10. Fe: Iron<br>\n",
        "   11. Type of glass: (class attribute)<br>\n",
        "      -- 1 building_windows_float_processed<br>\n",
        "      -- 2 building_windows_non_float_processed<br>\n",
        "      -- 3 vehicle_windows_float_processed<br>\n",
        "      -- 4 vehicle_windows_non_float_processed (none in this database)<br>\n",
        "      -- 5 containers<br>\n",
        "      -- 6 tableware<br>\n",
        "      -- 7 headlamps<br>\n",
        "\n",
        "8. Missing Attribute Values: None\n",
        "\n",
        "9. Class Distribution: (out of 214 total instances)<br>\n",
        "  **163 Window glass (building windows and vehicle windows)**<br>\n",
        "      -- 87 float processed  <br>\n",
        "      -- 70 building windows<br>\n",
        "      -- 17 vehicle windows<br>\n",
        "      -- 76 non-float processed<br>\n",
        "      -- 76 building windows<br>\n",
        "      -- 0 vehicle windows<br>\n",
        "  **51 Non-window glass<br>**\n",
        "      -- 13 containers<br>\n",
        "      -- 9 tableware<br>\n",
        "      -- 29 headlamps<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTFJX0g9sqhI"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4nk7oP52RZ7"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv7qQl91vYPS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scikitplot.metrics import plot_roc\n",
        "from scikitplot.metrics import plot_precision_recall\n",
        "from imblearn.under_sampling import ClusterCentroids\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFobNfywuM-X"
      },
      "source": [
        "**Load the dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xohf2cI2r5Iu"
      },
      "source": [
        "df = pd.read_csv('glass.csv', skiprows=1)\n",
        "df.columns=['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','Type']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jaxnj3kswKo"
      },
      "source": [
        "features = []\n",
        "for feature in df.columns:\n",
        "    if feature != 'Type':\n",
        "        features.append(feature)\n",
        "X = df[features]\n",
        "y = df['Type']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTZptWRLtEVS"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZdYcVaQuXkZ"
      },
      "source": [
        "**Split into training and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahwZI4X-vUdt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXmBn7pud7T"
      },
      "source": [
        "**Note the imbalanced dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zF1c_9sviq1"
      },
      "source": [
        "count = y_train.value_counts()\n",
        "count.plot.bar()\n",
        "plt.ylabel('Number of records')\n",
        "plt.xlabel('Glass Type')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OPzjyOrukLN"
      },
      "source": [
        "**Create and train a model.** <br>\n",
        "**Then test it** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLIPfk_C2ZdF"
      },
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_score = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbtc1-cM2ylz"
      },
      "source": [
        "plot_roc(y_test, y_score)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kl_Cgc_21Xq"
      },
      "source": [
        "plot_precision_recall(y_test, y_score)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfoRhFYUuzD_"
      },
      "source": [
        "**The median number of samples for all columns**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at_M_-lv8Tc0"
      },
      "source": [
        "n_samples = int(count.median())\n",
        "print(n_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksnagq240jW1"
      },
      "source": [
        "Define a function that either undersamples or oversamples, depending on the 't' input parameter.<br>\n",
        "\n",
        "if t= under, then undersample the larger columns<br>\n",
        "if t= over, oversample the smaller columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0m7mZLa8idb"
      },
      "source": [
        "def sampling_strategy(X,y,n_samples,t):\n",
        "    target_classes = ''\n",
        "    if t == 'under':\n",
        "        target_classes = y.value_counts() > n_samples\n",
        "    elif t == 'over':\n",
        "        target_classes = y.value_counts() < n_samples\n",
        "    tc = target_classes[target_classes == True].index\n",
        "    target_classes_all = y.value_counts().index\n",
        "    columns = {}\n",
        "    for target in tc:\n",
        "        columns[target] = n_samples\n",
        "    return columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqNduRqWvjHC"
      },
      "source": [
        "**Undersample the larger classes to get the median number of samples**<br>\n",
        "Use ClusterCentroids to undersample the larger classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1frYPus8mZ9"
      },
      "source": [
        "columns = sampling_strategy(X_train,y_train,n_samples,t='under')\n",
        "under_sample = ClusterCentroids(columns)\n",
        "X_under, y_under = under_sample.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7hjtugacLXc"
      },
      "source": [
        "y_under_s = pd.Series(y_under)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ksVsfj81mH"
      },
      "source": [
        "count = y_under_s.value_counts()\n",
        "count.plot.bar()\n",
        "plt.ylabel('Number of records')\n",
        "plt.xlabel('Glass Type')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DibhW93T2JT7"
      },
      "source": [
        "**Oversample the smaller classes using SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pyzzk6NfSex"
      },
      "source": [
        "columns_under=sampling_strategy(X_under, y_under_s,n_samples, t='over')\n",
        "over_sampler = SMOTE(columns_under,k_neighbors=2)\n",
        "X_bal, y_bal = over_sampler.fit_resample(X_under, y_under)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y1Am4nNgMV9"
      },
      "source": [
        "y_bal_s=pd.Series(y_bal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ureeXtsF2VGa"
      },
      "source": [
        "**The dataset is now balanced 19 instances in each class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOWjwSwWf6Rm"
      },
      "source": [
        "count = y_bal_s.value_counts()\n",
        "count.plot.bar()\n",
        "plt.ylabel('Number of records')\n",
        "plt.xlabel('Glass Type')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWhB_Rj72iRZ"
      },
      "source": [
        "**Create and train a model on the balanced dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0iHff6TgtT_"
      },
      "source": [
        "model = KNeighborsClassifier()\n",
        "model.fit(X_bal, y_bal_s)\n",
        "y_score_balanced = model.predict_proba(X_test)\n",
        "y_pred_balanced = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34SjmEzAaHZy"
      },
      "source": [
        "**Compare the imbalanced dataset performance to the balanced dataset performance**<br>\n",
        "Did balancing the dataset improve the performance of the model?<br>\n",
        "The ROC curve looks like it improved, but the precision-recall model did not. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws55krOTdY5a"
      },
      "source": [
        "Note: classes are 1,2,3,5,6,7 - 6 types of glass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCwuHg_UPwh"
      },
      "source": [
        "# Plot metrics \n",
        "plot_roc(y_test, y_score, title=\"Imbalanced Dataset ROC\")\n",
        "plot_roc(y_test, y_score_balanced, title=\"Balanced Dataset ROC\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWE_irGcVO2T"
      },
      "source": [
        "plot_precision_recall(y_test, y_score,title=\"Imbalanced Dataset Precision-Recall\")\n",
        "plot_precision_recall(y_test, y_score_balanced, title=\"Balanced Dataset Precision-Recall\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUkglCqBVzV3"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_metric=f1_score(y_test,y_pred,average=None)\n",
        "print(\"F1 score for each imbalanced class:\",f1_metric)\n",
        "\n",
        "f1_metric=f1_score(y_test,y_pred_balanced,average=None)\n",
        "print(\"F1 score for each balanced class  :\",f1_metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "Change the n_samples. <br>\n",
        "Is the median of all the classes the best choice?"
      ],
      "metadata": {
        "id": "3RynW_VPyCx2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvuFp2VGYZs3"
      },
      "source": [
        "# **Use the class_weights function when creating the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJhOr2hexDm"
      },
      "source": [
        "Recall the class_weights function will give more importance to the minority classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsFK8EfNeOxp"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "classes = np.unique(y_train)\n",
        "cw = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "cw=class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "weights = dict(zip(classes,cw))\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAwUjKCm1sqK"
      },
      "source": [
        "model = DecisionTreeClassifier(class_weight=weights)\n",
        "model.fit(X_train, y_train)\n",
        "y_score_weight = model.predict_proba(X_test)\n",
        "y_pred_weight = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfgBwFJB2y2A"
      },
      "source": [
        "# Plot metrics \n",
        "plot_roc(y_test, y_score, title=\"Imbalanced Dataset ROC\")\n",
        "plot_roc(y_test, y_score_weight, title=\"Weighted Dataset ROC\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az-Q26H_2gE8"
      },
      "source": [
        "plot_precision_recall(y_test, y_score,title=\"Imbalanced Dataset Precision-Recall\")\n",
        "plot_precision_recall(y_test, y_score_weight,title=\"Weighted Dataset Precision-Recall\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tczA4Sb914j4"
      },
      "source": [
        "#@title\n",
        "f1_metric=f1_score(y_test,y_pred,average=None)\n",
        "print(\"F1 score for each imbalanced class:\",f1_metric)\n",
        "\n",
        "f1_metric=f1_score(y_test,y_pred_weight,average=None)\n",
        "print(\"F1 score for each weighted class  :\",f1_metric)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}