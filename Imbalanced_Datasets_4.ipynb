{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced Datasets 4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPeSmBIc4iV/g5sCUD17+zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Imbalanced_Datasets_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWjURKKtVzsG"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhtIbDyuV7sM"
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"image/\"+str(num)+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzc0lbrrUYN9"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1wdkEQve_G"
      },
      "source": [
        "# example of a roc auc for a predictive model\n",
        "from sklearn.datasets import make_classification \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfSqduTUcJv"
      },
      "source": [
        "**Create a dataset of two classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUxDFwfovija"
      },
      "source": [
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BKgHQHUvnJ6"
      },
      "source": [
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEzySg0XUT1_"
      },
      "source": [
        "**DummyClassifier is a classifier that makes predictions using simple rules**.<br>\n",
        "\n",
        "This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS6zsbTGvrQk"
      },
      "source": [
        "# no skill model, stratified random class predictions\n",
        "model = DummyClassifier(strategy='stratified') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "pos_probs = yhat[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vq9QQxPc7oh"
      },
      "source": [
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, pos_probs) \n",
        "print('No Skill ROC AUC %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R0TFqkoVoEt"
      },
      "source": [
        "Image(\"images/AUC\"+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSEFxaOPvv9n"
      },
      "source": [
        "# skilled model\n",
        "model = LogisticRegression(solver='lbfgs') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX) \n",
        "pos_probs = yhat[:, 1]\n",
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, pos_probs) \n",
        "print('Logistic ROC AUC %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnhAM4cvdUg0"
      },
      "source": [
        "# example of a precision-recall curve for a predictive model\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from matplotlib import pyplot\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2) # fit a model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "# predict probabilities\n",
        "yhat = model.predict_proba(testX)\n",
        "# retrieve just the probabilities for the positive class\n",
        "pos_probs = yhat[:, 1]\n",
        "# calculate the no skill line as the proportion of the positive class\n",
        "no_skill = len(y[y==1]) / len(y)\n",
        "# plot the no skill precision-recall curve\n",
        "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "# calculate model precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(testy, pos_probs)\n",
        "# plot the model precision-recall curve\n",
        "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeuQSYzVdfHl"
      },
      "source": [
        "# example of a precision-recall auc for a predictive model\n",
        "from sklearn.datasets import make_classification \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import precision_recall_curve \n",
        "from sklearn.metrics import auc\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
        "# no skill model, stratified random class predictions\n",
        "model = DummyClassifier(strategy='stratified') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "pos_probs = yhat[:, 1]\n",
        "# calculate the precision-recall auc\n",
        "precision, recall, _ = precision_recall_curve(testy, pos_probs) \n",
        "auc_score = auc(recall, precision)\n",
        "print('No Skill PR AUC: %.3f' % auc_score)\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX) \n",
        "pos_probs = yhat[:, 1]\n",
        "# calculate the precision-recall auc\n",
        "precision, recall, _ = precision_recall_curve(testy, pos_probs) \n",
        "auc_score = auc(recall, precision)\n",
        "print('Logistic PR AUC: %.3f' % auc_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwiAfxxHdu0u"
      },
      "source": [
        "# create an imbalanced dataset\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01],\n",
        "random_state=1)\n",
        "# split into train/test sets with same class ratio\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
        "# summarize dataset\n",
        "print('Dataset: Class0=%d, Class1=%d' % (len(y[y==0]), len(y[y==1])))\n",
        "print('Train: Class0=%d, Class1=%d' % (len(trainy[trainy==0]), len(trainy[trainy==1]))) \n",
        "print('Test: Class0=%d, Class1=%d' % (len(testy[testy==0]), len(testy[testy==1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aRLbsOAd02T"
      },
      "source": [
        "# roc curve and roc auc on an imbalanced dataset\n",
        "from sklearn.datasets import make_classification \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "         \n",
        "# plot no skill and model roc curves\n",
        "def plot_roc_curve(test_y, naive_probs, model_probs):\n",
        "  # plot naive skill roc curve\n",
        "  fpr, tpr, _ = roc_curve(test_y, naive_probs) \n",
        "  pyplot.plot(fpr, tpr, linestyle='--', label='No Skill') \n",
        "  # plot model roc curve\n",
        "  fpr, tpr, _ = roc_curve(test_y, model_probs) \n",
        "  pyplot.plot(fpr, tpr, marker='.', label='Logistic') \n",
        "  # axis labels\n",
        "  pyplot.xlabel('False Positive Rate') \n",
        "  pyplot.ylabel('True Positive Rate')\n",
        "  # show the legend\n",
        "  pyplot.legend()\n",
        "  # show the plot\n",
        "  pyplot.show()\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
        "# split into train/test sets with same class ratio\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
        "# no skill model, stratified random class predictions\n",
        "model = DummyClassifier(strategy='stratified') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "naive_probs = yhat[:, 1]\n",
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, naive_probs) \n",
        "print('No Skill ROC AUC %.3f' % roc_auc)\n",
        "# skilled model\n",
        "model = LogisticRegression(solver='lbfgs') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX) \n",
        "model_probs = yhat[:, 1]\n",
        "# calculate roc auc\n",
        "roc_auc = roc_auc_score(testy, model_probs) \n",
        "print('Logistic ROC AUC %.3f' % roc_auc)\n",
        "# plot roc curves\n",
        "plot_roc_curve(testy, naive_probs, model_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWBftkleeX6P"
      },
      "source": [
        "# pr curve and pr auc on an imbalanced dataset\n",
        "from sklearn.datasets import make_classification \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import precision_recall_curve \n",
        "from sklearn.metrics import auc\n",
        "from matplotlib import pyplot\n",
        "# plot no skill and model precision-recall curves\n",
        "def plot_pr_curve(test_y, model_probs):\n",
        "  # calculate the no skill line as the proportion of the positive class no_skill = len(test_y[test_y==1]) / len(test_y)\n",
        "  # plot the no skill precision-recall curve\n",
        "  pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill') \n",
        "  # plot model precision-recall curve\n",
        "  precision, recall, _ = precision_recall_curve(testy, model_probs)\n",
        "  pyplot.plot(recall, precision, marker='.', label='Logistic') # axis labels\n",
        "  pyplot.xlabel('Recall')\n",
        "  pyplot.ylabel('Precision')\n",
        "  # show the legend\n",
        "  pyplot.legend()\n",
        "  # show the plot\n",
        "  pyplot.show()\n",
        "\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
        "# split into train/test sets with same class ratio\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
        "# no skill model, stratified random class predictions\n",
        "model = DummyClassifier(strategy='stratified') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX)\n",
        "naive_probs = yhat[:, 1]\n",
        "# calculate the precision-recall auc\n",
        "precision, recall, _ = precision_recall_curve(testy, naive_probs) \n",
        "auc_score = auc(recall, precision)\n",
        "print('No Skill PR AUC: %.3f' % auc_score)\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs') \n",
        "model.fit(trainX, trainy)\n",
        "yhat = model.predict_proba(testX) \n",
        "model_probs = yhat[:, 1]\n",
        "# calculate the precision-recall auc\n",
        "precision, recall, _ = precision_recall_curve(testy, model_probs) \n",
        "auc_score = auc(recall, precision)\n",
        "print('Logistic PR AUC: %.3f' % auc_score)\n",
        "# plot precision-recall curves\n",
        "plot_pr_curve(testy, model_probs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXnty2WUe_2v"
      },
      "source": [
        "# summarize the distribution of predicted probabilities\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01],\n",
        "random_state=1)\n",
        "# split into train/test sets with same class ratio\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs') \n",
        "model.fit(trainX, trainy)\n",
        "# predict probabilities\n",
        "yhat = model.predict_proba(testX)\n",
        "# retrieve just the probabilities for the positive class\n",
        "pos_probs = yhat[:, 1]\n",
        "# predict class labels\n",
        "yhat = model.predict(testX)\n",
        "# summarize the distribution of class labels\n",
        "print(Counter(yhat))\n",
        "# create a histogram of the predicted probabilities \n",
        "pyplot.hist(pos_probs, bins=100)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}