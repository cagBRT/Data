{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7:AutomaticOutlierDetection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPiHy2QSEWrDmAbquEXEwSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/7_AutomaticOutlierDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsTUH5TTFPt9"
      },
      "source": [
        "There are three notebooks in the Outliers section:<br>\n",
        "1. This notebook\n",
        "2. [InterquartileRange](https://colab.research.google.com/github/cagBRT/Data/blob/main/6_InterquartileRange.ipynb)\n",
        "3. [AutomaticOutlierDetection](https://colab.research.google.com/github/cagBRT/Data/blob/main/7_AutomaticOutlierDetection.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYOZ-KWWHkQo"
      },
      "source": [
        "The seaborn pairplot takes a while to run. <br>\n",
        "Do the following: \n",
        "1.   Set Runtime type to GPU\n",
        "2.   Run All cells \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orPPDxtet-nl"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AL3QWvA2IvV"
      },
      "source": [
        "!pip install seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7trO53EuHl-"
      },
      "source": [
        "%matplotlib inline\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9MGf09LtcL2"
      },
      "source": [
        "A simple approach to identifying outliers is to locate those examples that are far from the other examples in the multi-dimensional feature space. This can work well for feature spaces with low dimensionality (few features), although it can become less reliable as the number of features is increased(AKA the curse of dimensionality)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATo9H1bZtp9d"
      },
      "source": [
        "The local outlier factor, or LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier detection. <br>\n",
        "Each example is assigned a scoring of how isolated or how likely it is to be an outlier based on the size of its local neighborhood. <br>\n",
        "Those examples with the largest score are more likely to be outliers. <br>\n",
        "The scikit-learn library provides an implementation of this approach in the LocalOutlierFactor class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHc9_HOVPD0o"
      },
      "source": [
        "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pLUc-xIPL-n"
      },
      "source": [
        "There are 14 attributes in each case of the dataset. They are:<br>\n",
        "CRIM - per capita crime rate by town<br>\n",
        "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.<br>\n",
        "INDUS - proportion of non-retail business acres per town.<br>\n",
        "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)<br>\n",
        "NOX - nitric oxides concentration (parts per 10 million)<br>\n",
        "RM - average number of rooms per dwelling<br>\n",
        "AGE - proportion of owner-occupied units built prior to 1940<br>\n",
        "DIS - weighted distances to five Boston employment centres<br>\n",
        "RAD - index of accessibility to radial highways<br>\n",
        "TAX - full-value property-tax rate per 10,000 dollars<br>\n",
        "PTRATIO - pupil-teacher ratio by town<br>\n",
        "Bk is the proportion of blacks by town<br>\n",
        "LSTAT - percentage of lower status of the population<br>\n",
        "MEDV - Median value of owner-occupied homes in $1000's<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yneXH-louOP1"
      },
      "source": [
        "# load the dataset\n",
        "df = pd.read_csv('Bostonhousing.csv', header=None)\n",
        "# retrieve the array\n",
        "data = df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Tyfs7B9YNo"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYI4-Z1g-C7E"
      },
      "source": [
        "sns.scatterplot( x=df[0], y=df[1], data=df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5WyCbYrE8_T"
      },
      "source": [
        "sns.pairplot(df, diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w_qy5eP_TNX"
      },
      "source": [
        "# split into input and output elements\n",
        "X, y = data[1:, :-1], data[1:, -1]\n",
        "# summarize the shape of the dataset\n",
        "print(X.shape, y.shape)\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
        "# summarize the shape of the train and test sets\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFstU9VPINmU"
      },
      "source": [
        "sns.pairplot(X_test, diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBaXfvRou2js"
      },
      "source": [
        "Use the Linear Regression model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JQDjHcBu1dZ"
      },
      "source": [
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aYDKZ_uvEhw"
      },
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSha0zZ5vEqQ"
      },
      "source": [
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat) \n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o4TeWya6f2G"
      },
      "source": [
        "**Remove outliers from the training dataset** <br>\n",
        "The tehory is the outliers are causing the linear regression model to learn a bias or skewed understanding of the problem. If the outliers are remvoed from the training set, this may result in a better  performing model. <br>\n",
        "We can do this by defining the LocalOutlierFactor model then use it to make a prediction on the training dataset, marking each row in the training dataset as normal(1) or an outlier (-1).<br>\n",
        "In this case the default parameters are used for the outlier detection model.  Although it is a good idea to tune the configuration to the specifics of your dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw3pQ7DP7NUo"
      },
      "source": [
        "# identify outliers in the training dataset\n",
        "lof = LocalOutlierFactor()\n",
        "yhat = lof.fit_predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9VSw1Pa7Z4v"
      },
      "source": [
        "**Remove the outliers from the training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znPXHGCR7f4s"
      },
      "source": [
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "X_train, y_train = X_train[mask, :], y_train[mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px6Aegwu7nte"
      },
      "source": [
        "# summarize the shape of the updated training dataset print(X_train.shape, y_train.shape)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7i6-_5I79Ei"
      },
      "source": [
        "Recall the trainig and test set shapes for the origial dataset, before the outliers were removed:<br>\n",
        "(339, 13) (167, 13) (339,) (167,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niznfr738JKV"
      },
      "source": [
        "Note the shape of the training set after the removal of the outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R7-qaNj7tnM"
      },
      "source": [
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}