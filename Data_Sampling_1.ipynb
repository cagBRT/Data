{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Sampling 1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMQOlJxT1gN1eQhEwpCvcl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Data_Sampling_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YltXI4oXCq-L"
      },
      "source": [
        "#**Data Sampling:**<br>\n",
        "## **Oversampling and Undersampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-QIOQJ6o0NZ"
      },
      "source": [
        "Machine learning techniques can give misleadingly optimistic performance on classification datasets when there is an imbalanced class distribution. <br>\n",
        "\n",
        "Many machine learning algorithms are designed to operate on classification data with an equal number of observations for each class. <br>\n",
        "\n",
        "When the dataset is imbalanced, algorithms can learn that the minority class examples are not important. Which means they can be ignored for the sake of performance.<br>\n",
        "\n",
        "Decision trees, k-nearest neighbors, and neural networks, learn that the minority class is not as important as the majority class and put more attention and perform better on the majority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirI2F4qr6AF"
      },
      "source": [
        "Imbalanced datasets are those where there is a severe skew in the class distribution, such as 1:100 or 1:1000 examples in the minority class to the majority class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xApQVfCxr_kI"
      },
      "source": [
        "- Random sampling provides a naive technique for rebalancing the class distribution for an imbalanced dataset.<br>\n",
        "- Random oversampling duplicates examples from the minority class in the training dataset and can result in overfitting for some models.<br>\n",
        "- Random undersampling deletes examples from the majority class and can result in losing information invaluable to a model.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WmppMlMB0oT"
      },
      "source": [
        "The most popular solution to an imbalanced classification problem is to change the composition of the training dataset.\n",
        "<br>\n",
        "\n",
        "Techniques designed to change the class distribution in the training dataset are generally referred to as sampling methods as we are sampling an existing data sample.<br>\n",
        "\n",
        "If the sampling is balanced, many ML algorithms can be used on the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1He2Pd5CaGn"
      },
      "source": [
        "**Sampling is only performed on the training dataset**.<br>\n",
        "\n",
        "There are many data sampling methods to use for balancing class distribution in the training set.<br>\n",
        "\n",
        "There is no best data sampling method, the best method is the one that works best on your data. <br>\n",
        "\n",
        "Sampling methods behave differently depending on the ML algorithm and the training dataset.\n",
        "\n",
        "Sampling is not performed on the holdout test or validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8J0AweCyZbI"
      },
      "source": [
        "# **Use Random oversampling to balance the class distribution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6eWhv6Gz7VO"
      },
      "source": [
        "Oversampling and undersampling can be used for two-class (binary) classification problems and multiclass classification problems with one or more majority or minority classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KZZ4JypzhDw"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ubv8cAykyb"
      },
      "source": [
        "# example of random oversampling to balance the class distribution\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8yGFj07ypS9"
      },
      "source": [
        "**Create a dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w2643FlyoL-"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOx911aytuG"
      },
      "source": [
        "**Use oversampling on the minority class**<br>\n",
        "This method randomly duplicating examples from the minority class in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QylOGo5rkUKM"
      },
      "source": [
        "\n",
        "# summarize class distribution\n",
        "print(\"Before resample:\",Counter(y))\n",
        "# define oversampling strategy\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "# fit and apply the transform\n",
        "X_over, y_over = oversample.fit_resample(X, y)\n",
        "# summarize class distribution\n",
        "print(\"After resample:\",Counter(y_over))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP_qRcn70TyX"
      },
      "source": [
        "# **Using a pipeline to perform Random Oversampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BeDw74B0gBo"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbEmgHrt0kU_"
      },
      "source": [
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyT4pGDL0o4j"
      },
      "source": [
        "**Define the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3KVeSH0wKD"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f73Cu67C0065"
      },
      "source": [
        "**Define the Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb5nLztn0z3P"
      },
      "source": [
        "# define pipeline\n",
        "steps = [('over', RandomOverSampler()), ('model', DecisionTreeClassifier())] \n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR4N-_Rr04lW"
      },
      "source": [
        "**Train the pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTD_hvz6sSio"
      },
      "source": [
        "# evaluate pipeline\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1) \n",
        "score = mean(scores)\n",
        "print('F-measure: %.3f' % score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LSMJMwx1Xc4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAbNF4qB1Zjy"
      },
      "source": [
        "# **Undersampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uamUQstS1izx"
      },
      "source": [
        "With Random undersampling randomly selected examples from the majority class deleted from the training dataset.<br>\n",
        "\n",
        "This technique reduces the number of examples in the majority class in the working version of the training dataset. \n",
        "\n",
        "Undersampling can be repeated multiple times to acheive the desired class distribution, for example: an equal number of examples for each class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5rO1QWx2Fex"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uWEWnyS2ILp"
      },
      "source": [
        "# example of random undersampling to balance the class distribution\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from numpy import mean\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s5spRK42Nnw"
      },
      "source": [
        "Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I8UYyPZ2Pc9"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPZIfPCR2SvI"
      },
      "source": [
        "Use undersample to reduce the size of the majority class in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEc8EYsDsnuc"
      },
      "source": [
        "# summarize class distribution\n",
        "print(\"Before undersampling:\",Counter(y))\n",
        "# define undersample strategy\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "# fit and apply the transform\n",
        "X_over, y_over = undersample.fit_resample(X, y)\n",
        "# summarize class distribution\n",
        "print(\"After undersampling:\",Counter(y_over))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-RYzo1c2-s8"
      },
      "source": [
        "**Create a dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78jaUZY-3CbA"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD3a-9iF3HfD"
      },
      "source": [
        "**Create the pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of0Wsy1t3Ju5"
      },
      "source": [
        "# define pipeline\n",
        "steps = [('under', RandomUnderSampler()), ('model', DecisionTreeClassifier())] \n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfHwZ73j2lki"
      },
      "source": [
        "**Undersampling using a pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfBs5fyossW8"
      },
      "source": [
        "# evaluate pipeline\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1) \n",
        "score = mean(scores)\n",
        "print('F-measure: %.3f' % score)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}