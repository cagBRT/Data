{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1:LowVarianceData.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMd2easTbXnHuzX5GB9YXq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/1_LowVarianceData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWJ3-hXvwqUa"
      },
      "source": [
        "Messy data sets need to be cleaned up before using them to train models<br>\n",
        "This notebook explores methods for finding duplicate and low variance data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh5oL6MJDNqC"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2vzpoFSxERF"
      },
      "source": [
        "This notebook uses:<br>\n",
        ">Oil spill dataset<br>\n",
        "By Robert Holte.<br>\n",
        "Kubat, M., Holte, R., & Matwin, S. (1998). Machine Learning for the Detection of Oil Spills in Satellite Radar Images. Machine Learning, 30, 195â€“215.<br>\n",
        "\n",
        "- 41 minority (oil slick)<br>\n",
        "- 896 majority (no oil slick)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4UiB-1PDbdR"
      },
      "source": [
        "**Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tszvac0E0YHR"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from numpy import loadtxt\n",
        "from numpy import unique\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yItuxFUu0Ymx"
      },
      "source": [
        "**Get the data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU6PngNX-dvU"
      },
      "source": [
        "# load the dataset\n",
        "df = read_csv(\"oil-spill.csv\", header=None)\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTMumvzvDu0V"
      },
      "source": [
        "Notice the column values are strings that are numbers. <br>\n",
        "This can be a little confusing when deleting columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqcgRfFV-heX"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxbhhluFM6K"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XkyfVFoEYg2"
      },
      "source": [
        "Column 49 is the label column for spill/no spill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAFPvidyFVWT"
      },
      "source": [
        "df.value_counts([49])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DAIPz6FD_7m"
      },
      "source": [
        "**Break off the labels from the features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhLC3U3OEYrH"
      },
      "source": [
        "labels=df[49]\n",
        "#The labels variable has the labels for the dataset\n",
        "print(labels.head())\n",
        "df_X=df.drop([49], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El5iRmYM9qoh"
      },
      "source": [
        "**Data Cleaning**<br>\n",
        "Step 1: Look for columns that have the same value for every row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZLQu-2a7_fC"
      },
      "source": [
        "# summarize the number of unique values in each column\n",
        "col_values=df_X.nunique()\n",
        "print(col_values)\n",
        "#the list is the number of unique values in each column. \n",
        "#There are 937 rows\n",
        "#Note there are several columns with low variance data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDUx4ekG-KLj"
      },
      "source": [
        "Drop the columns that have only one value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsqRAUkd-NOd"
      },
      "source": [
        "# record columns to delete\n",
        "to_del=[]\n",
        "for i in range(len(col_values)):\n",
        "  if col_values[i]==1:\n",
        "    to_del.append(i)\n",
        "print(\"Column(s) with one value:\",to_del)\n",
        "# drop useless columns\n",
        "for i in range(len(to_del)):\n",
        "  df_X_good=df_X.drop(to_del[i], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpSJNJWFE4CE"
      },
      "source": [
        "df_X_good is the dataset:<br>\n",
        " >without labels <br>\n",
        " with columns with only one value removed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHZOkoaAUQXt"
      },
      "source": [
        "df_X_good"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwEgvPE6ElC6"
      },
      "source": [
        "Note that coloumn 22 is gone, but the other columns still have their original values for names. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNsSPLBkE4vr"
      },
      "source": [
        "df_X_good.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpK6vckbAs4f"
      },
      "source": [
        "**What about columns with very few unique values?**<br>\n",
        "Method 1: look for columns where the ratio of unique values to rows is less than a set threshold.<br>\n",
        "Method 2: use the VarianceThreshold Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NkVXmfXFQFh"
      },
      "source": [
        "**Method 1**<br>\n",
        "Set a threshold for the ratio. <br>\n",
        "In this case it is set at .055<br>\n",
        "Look at each column<br>\n",
        "Calculate the variance .... (number of unique values)/(number of rows)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KozaTLdI_3H"
      },
      "source": [
        "#col_values has the number of unique values in each column\n",
        "col_values=df_X_good.nunique()\n",
        "#print(col_values)\n",
        "threshold=.055\n",
        "print(\"A list of low ratio columns:\\n\")\n",
        "for i in range(49):\n",
        "  #Column 22 was dropped because it had only one value\n",
        "  if i!=22:\n",
        "    calc=col_values[i]/637\n",
        "    if calc <= threshold:\n",
        "      print(\"unique values:%d row %d calc %.3f\" %(col_values[i],i, calc))\n",
        "calc=col_values[48]/637"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGi94PrykfQ"
      },
      "source": [
        "**Method 2**<br>\n",
        "Finding low variance in columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds6hAJS1Zxvx"
      },
      "source": [
        "**Dropping Low Variance Columns**<br>\n",
        "\n",
        "If the variance is low or close to zero, then a feature is approximately constant and will not improve the performance of the model. Then you should consider removing the column.<br>\n",
        "\n",
        "Or if only a handful of observations differ from a constant value, the variance will also be very low.<br>\n",
        "\n",
        "This situation, where a feature has been poorly evaluated, or brings little information because it is (almost) constant can be a justification to remove a column.<br>\n",
        "\n",
        "You may want to set an arbitrary variance threshold to determine which features are low variance and consider removing them. <br>\n",
        "\n",
        "Use trial and error by checking the accuracy of the predictions as a result of a feature removal to prove that justification for feature removal is correct. \n",
        "\n",
        "The variance threshold calculation depends on the probability density function of a particular distribution. For example if a feature has a normal distribution, use normal variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExeNwZBJzEs1"
      },
      "source": [
        "# define the transform\n",
        "transform = VarianceThreshold()\n",
        "# transform the input data\n",
        "X_sel = transform.fit_transform(df_X_good)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDM3fE-6ynfr"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "# define the location of the dataset\n",
        "df = read_csv('oil-spill.csv', header=None)\n",
        "# split data into inputs and outputs\n",
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "print(X.shape, y.shape)\n",
        "# define the transform\n",
        "transform = VarianceThreshold()\n",
        "# transform the input data\n",
        "X_sel = transform.fit_transform(X)\n",
        "print(X_sel.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHv2dUjczLB_"
      },
      "source": [
        "import numpy as np\n",
        "# define thresholds to check\n",
        "thresholds = np.arange(0.0, 0.55, 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VcJsDzzoRp"
      },
      "source": [
        "# apply transform with each threshold\n",
        "results = list()\n",
        "for t in thresholds:\n",
        " # define the transform\n",
        " transform = VarianceThreshold(threshold=t)\n",
        " # transform the input data\n",
        " #this will drop the low variance columns\n",
        " X_sel = transform.fit_transform(X)\n",
        " # determine the number of input features\n",
        " n_features = X_sel.shape[1]\n",
        " print('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
        " # store the result\n",
        " results.append(n_features) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miLr3MG40g2j"
      },
      "source": [
        "A line plot is then created showing the relationship between the threshold and the number of features in the transformed dataset.<br>\n",
        "\n",
        "We can see that even with a small threshold between 0.15 and 0.4, that a large number of features (14) are removed immediately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPzYlm1f0Abh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the threshold vs the number of selected features\n",
        "plt.plot(thresholds, results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyX3A4ITAdaZ"
      },
      "source": [
        "**Assignment**<br>\n",
        "1. Use the dataset called bank.csv<br>\n",
        "2. Determine if there are any columns that have a single value<br>\n",
        "3. Determine if there are any columns with low variance<br>\n",
        "4. If there are columns with low variance, should the column be deleted?"
      ]
    }
  ]
}