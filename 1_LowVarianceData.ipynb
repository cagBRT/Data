{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1:LowVarianceData.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO4yRLV52YPBpzl+Jc30NN2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/1_LowVarianceData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEVIxmUHWcLT"
      },
      "source": [
        "This is the first in a series of notebooks on preparing data for machine learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh5oL6MJDNqC"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Data.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ21wcw5XoD1"
      },
      "source": [
        "The image below shows the basic categories of data that must be addressed before using it to train a machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SpcIsZXWwPc"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"dataflowChart.png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWJ3-hXvwqUa"
      },
      "source": [
        "Messy data sets need to be cleaned before using them to train models<br>\n",
        "This notebook explores methods for finding low variance data columns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2vzpoFSxERF"
      },
      "source": [
        "This notebook uses:<br>\n",
        ">Oil spill dataset<br>\n",
        "By Robert Holte.<br>\n",
        "Kubat, M., Holte, R., & Matwin, S. (1998). Machine Learning for the Detection of Oil Spills in Satellite Radar Images. Machine Learning, 30, 195â€“215.<br>\n",
        "\n",
        "- 41 minority (oil slick)<br>\n",
        "- 896 majority (no oil slick)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4UiB-1PDbdR"
      },
      "source": [
        "**Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tszvac0E0YHR"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from numpy import loadtxt\n",
        "from numpy import unique\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yItuxFUu0Ymx"
      },
      "source": [
        "**Get the data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU6PngNX-dvU"
      },
      "source": [
        "# load the dataset\n",
        "df = read_csv(\"oil-spill.csv\", header=None)\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTMumvzvDu0V"
      },
      "source": [
        "Notice the column values are strings that are numbers. <br>\n",
        "This can be a little confusing when deleting columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqcgRfFV-heX"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxbhhluFM6K"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XkyfVFoEYg2"
      },
      "source": [
        "Column 49 is the label column for spill/no spill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAFPvidyFVWT"
      },
      "source": [
        "df.value_counts([49])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DAIPz6FD_7m"
      },
      "source": [
        "**Break off the labels from the features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhLC3U3OEYrH"
      },
      "source": [
        "labels=df[49]\n",
        "#The labels variable has the labels for the dataset\n",
        "print(labels.head())\n",
        "df_X=df.drop([49], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El5iRmYM9qoh"
      },
      "source": [
        "**Data Cleaning**<br>\n",
        "Step 1: Look for columns that have the same value for every row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZLQu-2a7_fC"
      },
      "source": [
        "# summarize the number of unique values in each column\n",
        "col_values=df_X.nunique()\n",
        "print(col_values)\n",
        "#the list is the number of unique values in each column. \n",
        "#There are 937 rows\n",
        "#Note there are several columns with low variance data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDUx4ekG-KLj"
      },
      "source": [
        "Drop the columns that have only one value<br>\n",
        "In this case, Column 22 has only one value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsqRAUkd-NOd"
      },
      "source": [
        "# record columns to delete\n",
        "to_del=[]\n",
        "for i in range(len(col_values)):\n",
        "  if col_values[i]==1:\n",
        "    to_del.append(i)\n",
        "print(\"Column(s) with one value:\",to_del)\n",
        "# drop useless columns\n",
        "df_X_good=df_X.drop(to_del, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoJ8CcMI22de"
      },
      "source": [
        "df_X_good=df_X.drop(to_del, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpSJNJWFE4CE"
      },
      "source": [
        "df_X_good is the dataset:<br>\n",
        " >without labels <br>\n",
        " with columns with only one value removed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHZOkoaAUQXt"
      },
      "source": [
        "df_X_good"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwEgvPE6ElC6"
      },
      "source": [
        "Note that coloumn 22 is gone, but the other columns still have their original values for names. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNsSPLBkE4vr"
      },
      "source": [
        "df_X_good.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpK6vckbAs4f"
      },
      "source": [
        "**What about columns with very few unique values?**<br>\n",
        "Method 1: look for columns where the ratio of unique values to rows is less than a set threshold.<br>\n",
        "Method 2: use the VarianceThreshold Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NkVXmfXFQFh"
      },
      "source": [
        "**Method 1**<br>\n",
        "Set a threshold for the ratio. <br>\n",
        "In this case it is set at .055<br>\n",
        "Look at each column<br>\n",
        "Calculate the variance .... (number of unique values)/(number of rows)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KozaTLdI_3H"
      },
      "source": [
        "#col_values has the number of unique values in each column\n",
        "col_values=df_X_good.nunique()\n",
        "#print(col_values)\n",
        "threshold=0.05\n",
        "print(\"A list of low ratio columns:\\n\")\n",
        "for i in range(49):\n",
        "  #Column 22 was dropped because it had only one value\n",
        "  if i!=22:\n",
        "    calc=col_values[i]/937\n",
        "    if calc <= threshold:\n",
        "      print(\"unique values:%d column %d calc %.3f\" %(col_values[i],i, calc))\n",
        "calc=col_values[48]/937"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGi94PrykfQ"
      },
      "source": [
        "**Method 2**<br>\n",
        "Finding low variance in columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds6hAJS1Zxvx"
      },
      "source": [
        "**Dropping Low Variance Columns**<br>\n",
        "\n",
        "If the variance is low or close to zero, then a feature is approximately constant and will not improve the performance of the model. Then you should consider removing the column.<br>\n",
        "\n",
        "Or if only a handful of observations differ from a constant value, the variance will also be very low.<br>\n",
        "\n",
        "This situation, where a feature has been poorly evaluated, or brings little information because it is (almost) constant can be a justification to remove a column.<br>\n",
        "\n",
        "You may want to set an arbitrary variance threshold to determine which features are low variance and consider removing them. <br>\n",
        "\n",
        "Use trial and error by checking the accuracy of the predictions as a result of a feature removal to prove that justification for feature removal is correct. \n",
        "\n",
        "The variance threshold calculation depends on the probability density function of a particular distribution. For example if a feature has a normal distribution, use normal variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odUATPgcoZgF"
      },
      "source": [
        "Below is a simple example of the VarianceThreshold function. <br>\n",
        "X_simple is a simple dataset of 3 rows, 4 columns<br>\n",
        "The default VarianceThreshold value is 0<br>\n",
        "When the fit_transform function is applied the columns with only one value are removed. <br>\n",
        "In this case it is column 0 and column 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8_Kn06koR1H"
      },
      "source": [
        "#Simple dataset to show VarianceThreshold\n",
        "X_simple = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n",
        "selector = VarianceThreshold()\n",
        "selector.fit_transform(X_simple)\n",
        "print(\"The columns that are low variance are false\")\n",
        "selector.get_support()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDM3fE-6ynfr"
      },
      "source": [
        "# define the location of the dataset\n",
        "df = read_csv('oil-spill.csv', header=None)\n",
        "# split data into inputs and outputs\n",
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHv2dUjczLB_"
      },
      "source": [
        "# define thresholds to check\n",
        "thresholds = np.arange(0.0, 0.55, 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VcJsDzzoRp"
      },
      "source": [
        "# apply transform with each threshold\n",
        "results = list()\n",
        "for t in thresholds:\n",
        "  # define the transform\n",
        "  transform = VarianceThreshold(threshold=t)\n",
        "  # transform the input data\n",
        "  #this will drop the low variance columns\n",
        "  X_sel = transform.fit_transform(X)\n",
        "  # determine the number of input features\n",
        "  n_features = X_sel.shape[1]\n",
        "  print('>Threshold=%.2f, Number of Features=%d' % (t, n_features))\n",
        "  # store the result\n",
        "  results.append(n_features) \n",
        "\n",
        "print(\"\\nColumns with low variance\")\n",
        "for i in range(len(transform.get_support())):\n",
        "  if transform.get_support()[i]==False:\n",
        "    print(\"col #\",i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miLr3MG40g2j"
      },
      "source": [
        "A line plot is then created showing the relationship between the threshold and the number of features in the transformed dataset.<br>\n",
        "\n",
        "We can see that even with a small threshold between 0.15 and 0.4, that a large number of features (14) are removed immediately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPzYlm1f0Abh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the threshold vs the number of selected features\n",
        "plt.plot(thresholds, results)\n",
        "plt.xlabel(\"thresholds\")\n",
        "plt.ylabel(\"number of features\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyX3A4ITAdaZ"
      },
      "source": [
        "**Assignment**<br>\n",
        "1. Use the dataset called bank.csv<br>\n",
        "2. Determine if there are any columns that have a single value<br>\n",
        "3. Determine if there are any columns with low variance<br>\n",
        "4. If there are columns with low variance, should the column be deleted?\n",
        "\n",
        "<br>\n",
        "Hint: read_csv(\"bank.csv\", header='infer' , delimiter=';')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkZLdtSJLaRM"
      },
      "source": [
        "%cd /content/cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4258jIQM7_Er"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP6v8HEhGgjy"
      },
      "source": [
        "bankData=pd.read_csv(\"bank.csv\", header='infer' , delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI0inxp9-UuD"
      },
      "source": [
        "bankData.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tszocF9N6di"
      },
      "source": [
        "percent_missing = bankData.isnull().sum() * 100 / len(bankData)\n",
        "missing_values = pd.DataFrame({'percent_missing': percent_missing})\n",
        "missing_values.sort_values(by ='percent_missing' , ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqBhS5kgGlzx"
      },
      "source": [
        "bankData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nspRRq8V6oAM"
      },
      "source": [
        "Copy the labels (the 'y' column) from the data <br>\n",
        "Then drop the label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5PQryy-PBxy"
      },
      "source": [
        "labels =bankData['y']\n",
        "bankData_X=bankData.drop(['y'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UuqW0Ce62AP"
      },
      "source": [
        "Convert the catagorical data to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNfTDyFo6V4h"
      },
      "source": [
        "#Convert the catagorical data to one-hot encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRzBE_j69Dt"
      },
      "source": [
        "Now: Determine the columns that have low variance.<br>\n",
        "Given code is for the oil spill data. <br>\n",
        "Modify it for the bank data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdDRlSR94sdk"
      },
      "source": [
        "#Assignment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAC7Q-Bn7VJu",
        "cellView": "code"
      },
      "source": [
        "#@title \n",
        "#col_values has the number of unique values in each column\n",
        "assign_col_values=bankData_X.nunique()\n",
        "#print(col_values)\n",
        "threshold=0.05\n",
        "print(\"A list of low ratio columns:\\n\")\n",
        "for i in range(16):\n",
        "  #Column 22 was dropped because it had only one value\n",
        "  if i != 22:\n",
        "    calc=assign_col_values[i]/937\n",
        "    if calc <= threshold:\n",
        "      print(\"unique values:%d col %d calc %.3f\" %(col_values[i],i, calc))\n",
        "calc=assign_col_values[15]/X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}