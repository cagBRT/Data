{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomalies 2: Isolation Forest.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNF8hnDu/nRjbxxYrgrw0Ap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Data/blob/main/Anomalies_2_Isolation_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXgNXFH51KUZ"
      },
      "source": [
        "In this notebook we are using an isolation forest for anomly detection."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The IsolationForest** ‘isolates’ observations by randomly selecting<br>\n",
        "a feature and then randomly selecting a split value between<br>\n",
        "the maximum and minimum values of the selected feature."
      ],
      "metadata": {
        "id": "OK3IpFUR5gbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(url=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5UGQoBaapqYa-SxGscx7Ow.gif\", width=600)"
      ],
      "metadata": {
        "id": "FWSxgNtfsNUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have seen a number of methods to detect outliers, namely, the Z-Score and Interquartile Range methods. <br>\n",
        "\n",
        "They are effective when the *underlying data follows a normal distribution* <br>(a distribution where most data points are closer to the mean and become less frequent as the distance to the mean increases). <br>\n",
        "\n",
        "If the data does not have a normal distribution, then these methods may incorrectly classify normal observations as outliers.<br>\n",
        "\n",
        "The Isolation Forest method is non-parametric, <br>\n",
        "which means that we don’t have to make assumptions about how the underlying data is distributed."
      ],
      "metadata": {
        "id": "lC64jT2VuiRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We detect anomalies (outliers) to treat them before conducting data analyses.<br>\n",
        "The anomaly detection technique can also be used to detect fraudulent credit card spending"
      ],
      "metadata": {
        "id": "q1ZoIkpFtrZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_bwvSVSryMzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChZrb8Q02Xy"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "#create a simple dataset\n",
        "X = [[-1.1], [0.3], [0.5], [100]]\n",
        "#train the model on the dataset\n",
        "clf = IsolationForest(random_state=0).fit(X)\n",
        "#predict the class of the following examples\n",
        "clf.predict([[0.1], [0], [90]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_outliers = 120, 40\n",
        "rng = np.random.RandomState(0)\n",
        "covariance = np.array([[0.5, -0.1], [0.7, 0.4]])\n",
        "cluster_1 = 0.4 * rng.randn(n_samples, 2) @ covariance + np.array([2, 2])  # general\n",
        "cluster_2 = 0.3 * rng.randn(n_samples, 2) + np.array([-2, -2])  # spherical\n",
        "outliers = rng.uniform(low=-4, high=4, size=(n_outliers, 2))\n",
        "\n",
        "X = np.concatenate([cluster_1, cluster_2, outliers])\n",
        "y = np.concatenate(\n",
        "    [np.ones((2 * n_samples), dtype=int), -np.ones((n_outliers), dtype=int)]\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "RmWBQvm6yHgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
        "handles, labels = scatter.legend_elements()\n",
        "plt.axis(\"square\")\n",
        "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
        "plt.title(\"Gaussian inliers with \\nuniformly distributed outliers\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XT7Xr8D0yRpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "clf = IsolationForest(max_samples=100, random_state=0)\n",
        "clf.fit(X_train)"
      ],
      "metadata": {
        "id": "3d4lZlwDyWN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "disp = DecisionBoundaryDisplay.from_estimator(\n",
        "    clf,\n",
        "    X,\n",
        "    response_method=\"predict\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
        "disp.ax_.set_title(\"Binary decision boundary \\nof IsolationForest\")\n",
        "plt.axis(\"square\")\n",
        "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8jazpgiEyZAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = DecisionBoundaryDisplay.from_estimator(\n",
        "    clf,\n",
        "    X,\n",
        "    response_method=\"decision_function\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
        "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
        "plt.axis(\"square\")\n",
        "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
        "plt.colorbar(disp.ax_.collections[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H34D1kNbyc9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkn9A4kKqKTJ"
      },
      "source": [
        "# **Isolation Forest for Anomaly Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z-Score and Interquartile Range methods identify at the variable level. <br>\n",
        "If you have reason to believe that multiple variables interact with each other and create outliers,<br>\n",
        "these methods will not be able to detect those outliers. <br>\n",
        "\n",
        "For example:<br>\n",
        ">an SAT score of 1350/1600 (90th percentile) does not seem to be an outlier by itself. <br>\n",
        "However, if we introduce another dimension, age,<br>\n",
        "we find that a 12-year-old got 1350/1600, <br>\n",
        "this observation is likely an outlier for a sub-sample of 12-year-olds. <br>\n",
        "\n",
        "Unlike single-variable outlier detection methods, <br>\n",
        "**Isolation Forest detects outliers in multi-dimensional space**."
      ],
      "metadata": {
        "id": "R8BR7yRVvY7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isolation Forest randomly cuts a given sample until a point is isolated."
      ],
      "metadata": {
        "id": "jjsGE5wfvxI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw in the Gif above, that it took four splits to isolate an outlier. <br>\n",
        "\n",
        "Let's now use Isolation Forest to isolate a normal point. <br>\n",
        "\n",
        "You'll see it takes many more splits to isolate a normal point. When using Isolation Forest, an outlier takes only a few splits, a normal datapoint will take many more."
      ],
      "metadata": {
        "id": "I2Yy58jAwBeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TgjBE1oHI9KNHoAj-imsGA.gif\", width=600)"
      ],
      "metadata": {
        "id": "5sLn2p_1wPkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Isolation Forest Algorithmm**\n",
        "\n",
        "First, the algorithm creates an isolation tree by going through the following steps:\n",
        "1. Randomly select a sub-sample (Sci-kit learn’s default: 100 instances/data points)\n",
        "2. Select a point to isolate.\n",
        "3. Randomly select a feature (i.e., variable) from the set of features X.\n",
        "4. Randomly select a threshold between the minimum and the maximum value of the feature x.\n",
        "5. If the data point is less (greater) than the threshold, then it flows through the left branch of the tree (right).<br>\n",
        "In other words, define the new minimum (maximum) of the range to the threshold for the next iteration.\n",
        "6. Repeat steps 3 through 5 until the point is isolated or until a pre-defined max number of iterations is reached.\n",
        "7. Record the number of times the steps 3 through 5 were repeated.\n",
        "\n"
      ],
      "metadata": {
        "id": "mtk5HFb4xQhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Isolation Forest algorithm requires us to pick the percentage of anomalies in the dataset"
      ],
      "metadata": {
        "id": "WADee5TFxu-J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14gP0QL9qJr5"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z-dPxq-qVlX"
      },
      "source": [
        "**Create an imbalanced dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lctURCb1qT-G"
      },
      "source": [
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.999], flip_y=0, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqRTdIzXsW6v"
      },
      "source": [
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySJrh_RcxJoQ"
      },
      "source": [
        "**Create and train an IsolationForest model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtKjCg_2xY_I"
      },
      "source": [
        "Train on the majority class only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFtxR5VOzpfL"
      },
      "source": [
        "The amount of contamination of the data set, i.e. the proportion of outliers in the data set. Used when fitting to define the threshold on the scores of the samples.<br>\n",
        "\n",
        "The contamination should be either default or in the range (0, 0.5].\n",
        "\n",
        "The contamination value can effect model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pByVSjwbsg0F"
      },
      "source": [
        "model = IsolationForest(contamination=0.01)\n",
        "# fit on majority class\n",
        "trainX = trainX[trainy==0]\n",
        "model.fit(trainX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAg8s6FzE0y"
      },
      "source": [
        "Set outliers = -1 class<br>\n",
        "Set inliers = 1 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIEu4nJxk7P"
      },
      "source": [
        "yhat = model.predict(testX)\n",
        "# mark inliers 1, outliers -1\n",
        "testy[testy == 1] = -1\n",
        "testy[testy == 0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DYSWxIhpkB6"
      },
      "source": [
        "score = f1_score(testy, yhat, pos_label=-1)\n",
        "print('F-measure: %.3f' % score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o0ZmR2etRPt"
      },
      "source": [
        "pyplot.scatter(testX[:, 0], yhat, s=30, label='prediction')\n",
        "pyplot.scatter(testX[:, 0], testy, color='red', s=3,label='ground truth')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xattx4S0lwg"
      },
      "source": [
        "**Assignment**<br>\n",
        "1. Change the contamination value to get a better F score\n",
        "2. Try different datasets to determine the effect on the performance\n"
      ]
    }
  ]
}